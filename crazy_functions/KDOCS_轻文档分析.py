#! .\venv\
# encoding: utf-8
# @Time   : 2023/6/15
# @Author : Spike
# @Descr   :
import time

from crazy_functions import crazy_box
from comm_tools.toolbox import update_ui
from comm_tools.toolbox import CatchException
from crazy_functions import crazy_utils
from request_llm import bridge_all
from comm_tools import prompt_generator, func_box, ocr_tools
import traceback


def Kdocs_è½»æ–‡æ¡£æ‰¹é‡å¤„ç†(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port):
    link = str(link_limit).split()
    links = []
    for i in link:
        if i.startswith('http'):
            links.append(i)
    if not links:
        chatbot.append((None, f'è¾“å…¥æ¡†ç©ºç©ºå¦‚ä¹Ÿï¼Ÿ{link}\n\n'
                              'è¯·åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥éœ€è¦è§£æçš„è½»æ–‡æ¡£é“¾æ¥ï¼Œç‚¹å‡»æ’ä»¶æŒ‰é’®ï¼Œé“¾æ¥éœ€è¦æ˜¯å¯è®¿é—®çš„ï¼Œå¦‚ä»¥ä¸‹æ ¼å¼ï¼Œå¦‚æœæœ‰å¤šä¸ªæ–‡æ¡£åˆ™ç”¨æ¢è¡Œæˆ–ç©ºæ ¼éš”å¼€'
                             f'\n\nã€é‡‘å±±æ–‡æ¡£ã€‘ xxxx https://kdocs.cn/l/xxxxxxxxxx'
                             f'\n\n https://kdocs.cn/l/xxxxxxxxxx'))
        yield from update_ui(chatbot, history)
        return
    file_limit = []
    img_ocr,  = crazy_box.json_args_return(plugin_kwargs, ['img_ocr'])
    for url in links:
        try:
            chatbot.append([link_limit+"\n\nç½‘é¡µçˆ¬è™«å‡†å¤‡å·¥ä½œä¸­ï½", None])
            yield from update_ui(chatbot, history)  #å¢åŠ ä¸­é—´è¿‡æ¸¡
            ovs_data, content, empty_picture_count, pic_dict = crazy_box.get_docs_content(url, image_processing=img_ocr)
            if img_ocr:
                ocr_process = f'æ£€æµ‹åˆ°è½»æ–‡æ¡£ä¸­å­˜åœ¨{func_box.html_tag_color(empty_picture_count)}å¼ å›¾ç‰‡ï¼Œä¸ºäº†äº§å‡ºç»“æœä¸å­˜åœ¨é—æ¼ï¼Œæ­£åœ¨é€ä¸€è¿›è¡Œè¯†åˆ«\n\n' \
                              f'> çº¢æ¡†ä¸ºé‡‡ç”¨çš„æ–‡æ¡ˆ,å¯ä¿¡åº¦ä½äº {llm_kwargs["ocr"]} å°†ä¸é‡‡ç”¨, å¯åœ¨Setting ä¸­è¿›è¡Œé…ç½®\n\n'
                chatbot.append([None, ocr_process])
                for i in pic_dict:
                    yield from update_ui(chatbot, history, 'æ­£åœ¨è°ƒç”¨OCRç»„ä»¶ï¼Œå›¾ç‰‡å¤šå¯èƒ½ä¼šæ¯”è¾ƒæ…¢')
                    img_content, img_result = ocr_tools.Paddle_ocr_select(ipaddr=llm_kwargs['ipaddr'], trust_value=llm_kwargs['ocr']).img_def_content(img_path=pic_dict[i])
                    content = str(content).replace(f"{i}", f"{func_box.html_local_img(img_result)}\n```{img_content}```")
                    ocr_process += f'{i} è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«æ•ˆæœå¦‚ä¸‹ {func_box.html_local_img(img_result)} \n\n'
                    chatbot[-1] = [None, ocr_process]
                    yield from update_ui(chatbot, history)
            else:
                if empty_picture_count >= 5:
                    chatbot.append([None, f'\n\n éœ€æ±‚æ–‡æ¡£ä¸­æ²¡æœ‰{func_box.html_tag_color("æè¿°")}çš„å›¾ç‰‡æ•°é‡' \
                                          f'æœ‰{func_box.html_tag_color(empty_picture_count)}å¼ ï¼Œç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹å¯èƒ½å­˜åœ¨é—æ¼ç‚¹ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹æ–¹æ³•å¯¹å›¾ç‰‡è¿›è¡Œæè¿°è¡¥å……ï¼Œæˆ–åœ¨æ’ä»¶é«˜çº§å‚æ•°ä¸­å¯ç”¨OCR\n\n' \
                                          f'{func_box.html_local_img("docs/imgs/pic_desc.png")}'])
                yield from update_ui(chatbot, history)
            title = content.splitlines()[0]
            file_limit.extend([title, content])
        except Exception as e:
            error_str = traceback.format_exc()
            chatbot.append([None, f'{func_box.html_a_blank(url)} \n\nè¯·æ£€æŸ¥ä¸€ä¸‹å“¦ï¼Œè¿™ä¸ªé“¾æ¥æˆ‘ä»¬è®¿é—®ä¸äº†ï¼Œæ˜¯å¦å¼€å¯åˆ†äº«ï¼Ÿæ˜¯å¦è®¾ç½®å¯†ç ï¼Ÿæ˜¯å¦æ˜¯è½»æ–‡æ¡£ï¼Ÿä¸‹é¢æ˜¯ä»€ä¹ˆé”™è¯¯ï¼Ÿ\n\n ```\n{str(error_str)}\n```'])
            yield from update_ui(chatbot, history)

    return file_limit

import re
def replace_special_chars(file_name):
    # é™¤äº†ä¸­æ–‡å¤–ï¼Œè¯¥æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»»ä½•ä¸€ä¸ªä¸æ˜¯æ•°å­—ã€å­—æ¯ã€ä¸‹åˆ’çº¿ã€.ã€ç©ºæ ¼çš„å­—ç¬¦
    return re.sub(r'[^\u4e00-\u9fa5\d\w\s\.\_]', '_', file_name)

def long_name_processing(file_name):
    if len(file_name) > 50:
        if file_name.find('"""') != -1:
            temp = file_name.split('"""')[1].splitlines()
            for i in temp:
                if i:
                    file_name = replace_special_chars(i)
                    break
        else:
            file_name = file_name[:20]
    return file_name


def write_test_cases(gpt_response_collection, inputs_show_user_array, llm_kwargs, chatbot, history):
    gpt_response = gpt_response_collection[1::2]
    chat_file_list = ''
    for k in range(len(gpt_response)):
        file_name = long_name_processing(inputs_show_user_array[k])
        test_case = []
        for i in gpt_response[k].splitlines():
            test_case.append([func_box.clean_br_string(i) for i in i.split('|')[1:]])
        file_path = crazy_box.ExcelHandle(ipaddr=llm_kwargs['ipaddr']).lpvoid_lpbuffe(test_case[2:], filename=file_name)
        chat_file_list += f'{file_name}ç”Ÿæˆç»“æœå¦‚ä¸‹:\t {func_box.html_download_blank(__href=file_path, file_name=file_path.split("/")[-1])}\n\n'
    chatbot.append(['Done', chat_file_list])
    yield from update_ui(chatbot, history)


def split_content_limit(inputs: str, llm_kwargs, chatbot, history) -> list:
    model = llm_kwargs['llm_model']
    max_length = llm_kwargs['max_length']/2  # è€ƒè™‘åˆ°å¯¹è¯+å›ç­”ä¼šè¶…è¿‡tokens,æ‰€ä»¥/2
    get_token_num = bridge_all.model_info[model]['token_cnt']
    if get_token_num(inputs) > max_length:
        chatbot.append([None, f'{func_box.html_tag_color(inputs[:10])}...å¯¹è¯é¢„è®¡è¶…å‡ºtokensé™åˆ¶, æ‹†åˆ†ä¸­...'])
        yield from update_ui(chatbot, history)
        segments = crazy_utils.breakdown_txt_to_satisfy_token_limit(inputs, get_token_num, max_length)
    else:
        segments = [inputs]
    return segments


def input_output_processing(gpt_response_collection, llm_kwargs, plugin_kwargs, chatbot, history, default_prompt: str = False, all_chat: bool = True):
    """
    Args:
        gpt_response_collection:  å¤šçº¿ç¨‹GPTçš„è¿”å›ç»“æœ
        plugin_kwargs: å¯¹è¯ä½¿ç”¨çš„æ’ä»¶å‚æ•°
        llm_kwargs:  å¯¹è¯+ç”¨æˆ·ä¿¡æ¯
        default_prompt: é»˜è®¤Prompt, å¦‚æœä¸ºFalseï¼Œåˆ™ä¸æ·»åŠ æç¤ºè¯
    Returns: ä¸‹æ¬¡ä½¿ç”¨ï¼Ÿ
        inputs_arrayï¼Œ inputs_show_user_array
    """
    inputs_array = []
    inputs_show_user_array = []
    kwargs_prompt, = crazy_box.json_args_return(plugin_kwargs, ['prompt'])
    if default_prompt: kwargs_prompt = default_prompt
    chatbot.append([f'æ¥ä¸‹æ¥ä½¿ç”¨çš„Promptæ˜¯ {func_box.html_tag_color(kwargs_prompt)} ï¼Œä½ å¯ä»¥åœ¨Promptç¼–è¾‘/æ£€ç´¢ä¸­è¿›è¡Œç§äººå®šåˆ¶å“¦ï½', None])
    time.sleep(1)
    prompt = prompt_generator.SqliteHandle(table=f'prompt_{llm_kwargs["ipaddr"]}').find_prompt_result(kwargs_prompt)
    for inputs, you_say in zip(gpt_response_collection[1::2], gpt_response_collection[0::2]):
        content_limit = yield from split_content_limit(inputs, llm_kwargs, chatbot, history)
        for limit in content_limit:
            inputs_array.append(prompt.replace('{{{v}}}', limit))
            inputs_show_user_array.append(you_say)
    yield from update_ui(chatbot, history)
    if all_chat:
        inputs_show_user_array = inputs_array
    else:
        inputs_show_user_array = default_prompt + ': ' + gpt_response_collection[0::2]
    return inputs_array, inputs_show_user_array


def submit_multithreaded_tasks(inputs_array, inputs_show_user_array, llm_kwargs, chatbot, history, plugin_kwargs):
    # æäº¤å¤šçº¿ç¨‹ä»»åŠ¡
    if len(inputs_array) == 1:
        yield from bridge_all.predict(inputs_array[0], llm_kwargs, plugin_kwargs, chatbot, history)
        gpt_response_collection = [inputs_show_user_array[0], history[-1]]
        # ä¸‹é¢çš„æ–¹æ³•æœ‰å†…å­˜æ³„æ¼?çš„é£é™©ï¼ˆåŠ è½½å®Œæ‰€æœ‰æ•°æ®åï¼Œè¿˜åœ¨ä¸çŸ¥é“è½®è¯¢ä»€ä¹ˆä¸œè¥¿ï¼‰ï¼Œæš‚æ—¶å±è”½
        # gpt_say = yield from crazy_utils.request_gpt_model_in_new_thread_with_ui_alive(
        #     inputs=inputs_array[0], inputs_show_user=inputs_array[0],
        #     llm_kwargs=llm_kwargs, chatbot=chatbot, history=[],
        #     sys_prompt="" , refresh_interval=0.1
        # )
        # gpt_response_collection = [inputs_show_user_array[0], gpt_say]
        # history.extend(gpt_response_collection)
    else:
        gpt_response_collection = yield from crazy_utils.request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency(
            inputs_array=inputs_array,
            inputs_show_user_array=inputs_show_user_array,
            llm_kwargs=llm_kwargs,
            chatbot=chatbot,
            history_array=[[""] for _ in range(len(inputs_array))],
            sys_prompt_array=["" for _ in range(len(inputs_array))],
            # max_workers=5,  # OpenAIæ‰€å…è®¸çš„æœ€å¤§å¹¶è¡Œè¿‡è½½
            scroller_max_len=80
        )
        # æ˜¯å¦å±•ç¤ºä»»åŠ¡ç»“æœ
        kwargs_is_show,  = crazy_box.json_args_return(plugin_kwargs, ['is_show'])
        if kwargs_is_show:
            for results in list(zip(gpt_response_collection[0::2], gpt_response_collection[1::2])):
                chatbot.append(results)
                history.extend(results)
                yield from update_ui(chatbot, history)
    return gpt_response_collection


def KDocs_è½¬Markdown(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port):
    file_limit = yield from Kdocs_è½»æ–‡æ¡£æ‰¹é‡å¤„ç†(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port)
    if not file_limit:
        yield from update_ui(chatbot=chatbot, history=history, msg='æ— æ³•è·å–éœ€æ±‚æ–‡æ¡£å†…å®¹ï¼Œæš‚åœè¿è¡Œ')
        return
    kwargs_to_mark, = crazy_box.json_args_return(plugin_kwargs, ['to_markdown'])
    if kwargs_to_mark:
        inputs_array, inputs_show_user_array = yield from input_output_processing(file_limit, llm_kwargs, plugin_kwargs,
                                                                           chatbot, history, default_prompt='æ–‡æ¡£è½¬Markdown')
        gpt_response_collection = yield from submit_multithreaded_tasks(inputs_array, inputs_show_user_array, llm_kwargs, chatbot, history, plugin_kwargs)
    else: gpt_response_collection = file_limit
    return gpt_response_collection


@CatchException
def éœ€æ±‚è½¬æµ‹è¯•ç”¨ä¾‹(file_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port):
    if file_limit:
        inputs_show_user_array = [str(file_limit).splitlines()[0]]
        file_limit = [inputs_show_user_array, file_limit]
        inputs_array, inputs_show_user_array = yield from input_output_processing(file_limit, llm_kwargs, plugin_kwargs,
                                                                       chatbot, history)
    else:
        chatbot.append((None, f'è¾“å…¥æ¡†ç©ºç©ºå¦‚ä¹Ÿï¼Ÿ\n\n'
                            'è¯·åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ä½ çš„éœ€æ±‚æ–‡æ¡£ï¼Œç„¶åå†ç‚¹å‡»éœ€æ±‚è½¬æµ‹è¯•ç”¨ä¾‹'))
        yield from update_ui(chatbot, history)
        return
    gpt_response_collection = yield from submit_multithreaded_tasks(inputs_array, inputs_show_user_array, llm_kwargs, chatbot, history, plugin_kwargs)
    write_test_cases(gpt_response_collection, inputs_show_user_array, llm_kwargs, chatbot, history)


@CatchException
def KDocs_è½¬æµ‹è¯•ç”¨ä¾‹(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port):
    gpt_response_collection = yield from KDocs_è½¬Markdown(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port)
    if not gpt_response_collection:
        yield from update_ui(chatbot=chatbot, history=history, msg='å¤šçº¿ç¨‹ä¸€ä¸ªéƒ½æ²¡æœ‰é€šè¿‡ï¼Œæš‚åœè¿è¡Œ')
        return
    inputs_array, inputs_show_user_array = yield from input_output_processing(gpt_response_collection, llm_kwargs, plugin_kwargs,
                                                                   chatbot, history)
    gpt_response_collection = yield from submit_multithreaded_tasks(inputs_array, inputs_show_user_array, llm_kwargs, chatbot, history, plugin_kwargs)
    yield from write_test_cases(gpt_response_collection, inputs_show_user_array, llm_kwargs, chatbot, history)
    yield from update_ui(chatbot, history, 'æ’ä»¶æ‰§è¡ŒæˆåŠŸ')


@CatchException
def KDocs_éœ€æ±‚åˆ†æé—®ç­”(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port):
    gpt_response_collection = yield from KDocs_è½¬Markdown(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port)
    if not gpt_response_collection:
        yield from update_ui(chatbot=chatbot, history=history, msg='å¤šçº¿ç¨‹ä¸€ä¸ªéƒ½æ²¡æœ‰é€šè¿‡ï¼Œæš‚åœè¿è¡Œ')
        return
    inputs_array, inputs_show_user_array = yield from input_output_processing(gpt_response_collection, llm_kwargs, plugin_kwargs,
                                                                   chatbot, history)
    gpt_response_collection = yield from submit_multithreaded_tasks(inputs_array, inputs_show_user_array, llm_kwargs, chatbot, history, plugin_kwargs)
    yield from update_ui(chatbot, history, 'æ’ä»¶æ‰§è¡ŒæˆåŠŸ')

def transfer_flow_chart(gpt_response_collection, llm_kwargs, chatbot, history):
    for inputs, you_say in zip(gpt_response_collection[1::2], gpt_response_collection[0::2]):
        chatbot.append([None, f'{long_name_processing(you_say)} ğŸƒğŸ»â€æ­£åœ¨åŠªåŠ›å°†Markdownè½¬æ¢ä¸ºæµç¨‹å›¾~'])
        md, html = crazy_box.Utils().markdown_to_flow_chart(data=inputs, hosts=llm_kwargs['ipaddr'], file_name=long_name_processing(you_say))
        chatbot.append(("View: " + func_box.html_view_blank(md), f'{func_box.html_iframe_code(html_file=html)}'
                                                               f'tips: åŒå‡»ç©ºç™½å¤„å¯ä»¥æ”¾å¤§ï½'
                                                               f'\n\n--- \n\n Download: {func_box.html_download_blank(html)}' 
                                                              '\n\n--- \n\n View: ' + func_box.html_view_blank(html)))
        yield from update_ui(chatbot=chatbot, history=history, msg='æˆåŠŸå†™å…¥æ–‡ä»¶ï¼')

@CatchException
def KDocs_æ–‡æ¡£è½¬æµç¨‹å›¾(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port):
    gpt_response_collection = yield from KDocs_è½¬Markdown(link_limit, llm_kwargs, plugin_kwargs, chatbot, history, system_prompt, web_port)
    if not gpt_response_collection:
        yield from update_ui(chatbot=chatbot, history=history, msg='å¤šçº¿ç¨‹ä¸€ä¸ªéƒ½æ²¡æœ‰é€šè¿‡ï¼Œæš‚åœè¿è¡Œ')
        return
    yield from transfer_flow_chart(gpt_response_collection, llm_kwargs, chatbot, history)
    yield from update_ui(chatbot, history, 'æ’ä»¶æ‰§è¡ŒæˆåŠŸ')


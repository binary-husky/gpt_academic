#! .\venv\
# encoding: utf-8
# @Time   : 2023/6/14
# @Author : Spike
# @Descr   :
import re, os
import json, time
from bs4 import BeautifulSoup
import requests
import sys
job_path = os.path.dirname(os.path.dirname(__file__))
sys.path.append(job_path)
import func_box
from toolbox import get_conf, update_ui
from openpyxl import load_workbook
import urllib.parse


class Utils:

    def __init__(self):
        self.find_keys_type = 'type'
        self.find_picture_source = {'caption': '', 'imgID': '', 'sourceKey': ''}
        self.find_keys_tags = ['picture', 'processon']

    def find_all_text_keys(self, dictionary, parent_type=None, text_values=None, filter_type='', img_proce=False):
        """
        Args:
            dictionary: å­—å…¸æˆ–åˆ—è¡¨
            parent_type: åŒ¹é…çš„typeï¼Œä½œä¸ºæ–°åˆ—è¡¨çš„keyï¼Œç”¨äºŽåˆ†ç±»
            text_values: å­˜å‚¨åˆ—è¡¨
            filter_type: å½“å‰å±‚çº§find_keys_type==filter_typeæ—¶ï¼Œä¸ç»§ç»­å¾€ä¸‹åµŒå¥—
        Returns:
            text_valueså’ŒæŽ’åºåŽçš„context_
        """
        # åˆå§‹åŒ– text_values ä¸ºç©ºåˆ—è¡¨ï¼Œç”¨äºŽå­˜å‚¨æ‰¾åˆ°çš„æ‰€æœ‰textå€¼
        if text_values is None:
            text_values = []
        # å¦‚æžœè¾“å…¥çš„dictionaryä¸æ˜¯å­—å…¸ç±»åž‹ï¼Œè¿”å›žå·²æ”¶é›†åˆ°çš„textå€¼
        if not isinstance(dictionary, dict):
            return text_values
        # èŽ·å–å½“å‰å±‚çº§çš„ type å€¼
        current_type = dictionary.get(self.find_keys_type, parent_type)
        # å¦‚æžœå­—å…¸ä¸­åŒ…å« 'text' æˆ– 'caption' é”®ï¼Œå°†å¯¹åº”çš„å€¼æ·»åŠ åˆ° text_values åˆ—è¡¨ä¸­
        if 'text' in dictionary:
            content_value = dictionary.get('text', None)
            text_values.append({current_type: content_value})
        if 'caption' in dictionary:
            temp = {}
            for key in self.find_picture_source:
                temp[key] = dictionary.get(key, None)
            text_values.append({current_type: temp})

        # å¦‚æžœå½“å‰ç±»åž‹ä¸ç­‰äºŽ filter_typeï¼Œåˆ™ç»§ç»­éåŽ†å­çº§å±žæ€§
        if current_type != filter_type:
            for key, value in dictionary.items():
                if isinstance(value, dict):
                    self.find_all_text_keys(value, current_type, text_values, filter_type)
                elif isinstance(value, list):
                    for item in value:
                        if isinstance(item, dict):
                            self.find_all_text_keys(item, current_type, text_values, filter_type)
        context_ = []
        pic_dict = {}
        for i in text_values:
            for key, value in i.items():
                if key in self.find_keys_tags:
                    if img_proce:
                        mark = '{{{%s}}}' % value['sourceKey']
                        context_.append(f'{key}OCRç»“æžœ: """{mark}"""\n{key}æè¿°: {value["caption"]}\n')
                        pic_dict[value['sourceKey']] = value['imgID']
                    else:
                        if value["caption"]: context_.append(f'{key}æè¿°: {value["caption"]}\n')
                        pic_dict[value['sourceKey']] = value['imgID']
                else:
                    context_.append(value)
        context_ = '\n'.join(context_)
        return text_values, context_, pic_dict

    def markdown_to_flow_chart(self, data, hosts, file_name):
        user_path = os.path.join(func_box.users_path, hosts)
        md_file = os.path.join(user_path, f"{file_name}.md")
        html_file = os.path.join(user_path, f"{file_name}.html")
        with open(file=md_file, mode='w') as f:
            f.write(data)
        func_box.Shell(f'npx markmap-cli --no-open "{md_file}" -o "{html_file}"').read()
        with open(file=html_file, mode='r') as f:
            html_code = f.read()
        return md_file, html_file, html_code


class ExcelHandle:

    def __init__(self, ipaddr):
        self.template_excel = os.path.join(func_box.base_path, 'docs/template/ã€Tempã€‘æµ‹è¯•è¦ç‚¹.xlsx')
        self.user_path = os.path.join(func_box.base_path, 'private_upload', ipaddr, 'test_case')
        os.makedirs(f'{self.user_path}', exist_ok=True)

    def lpvoid_lpbuffe(self, data_list: list, filename='', decs=''):
        # åŠ è½½çŽ°æœ‰çš„ Excel æ–‡ä»¶
        workbook = load_workbook(self.template_excel)
        # é€‰æ‹©è¦æ“ä½œçš„å·¥ä½œè¡¨
        worksheet = workbook['æµ‹è¯•è¦ç‚¹']
        decs_sheet = workbook['è¯´æ˜Ž']
        decs_sheet['C2'] = decs
        # å®šä¹‰èµ·å§‹è¡Œå·
        start_row = 4
        # éåŽ†æ•°æ®åˆ—è¡¨
        for row_data in data_list:
            # å†™å…¥æ¯ä¸€è¡Œçš„æ•°æ®åˆ°æŒ‡å®šçš„å•å…ƒæ ¼èŒƒå›´
            for col_num, value in enumerate(row_data, start=1):
                cell = worksheet.cell(row=start_row, column=col_num)
                cell.value = value
            # å¢žåŠ èµ·å§‹è¡Œå·
            start_row += 1
        # ä¿å­˜ Excel æ–‡ä»¶
        if filename == '': filename = time.strftime("%Y-%m-%d-%H", time.localtime()) + '_temp'
        test_case_path = f'{os.path.join(self.user_path, filename)}.xlsx'
        workbook.save(test_case_path)
        return test_case_path


class Kdocs:

    def __init__(self, url):
        WPS_COOKIES, WPS_HEADERS, WPS_OTL_PARM, \
        WPS_URL_OTL, WPS_SHAPES_PARM, WPS_URL_SHAPES = get_conf('WPS_COOKIES', 'WPS_HEADERS', 'WPS_OTL_PARM',
                                                                'WPS_URL_OTL', 'WPS_SHAPES_PARM', 'WPS_URL_SHAPES')
        self.url = url
        self.cookies = WPS_COOKIES
        self.headers = WPS_HEADERS
        self.parm_otl_data = WPS_OTL_PARM
        self.parm_shapes_data = WPS_SHAPES_PARM
        self.tol_url = WPS_URL_OTL
        self.shapes_url = WPS_URL_SHAPES

    def get_file_info(self):
        """
        èŽ·å–ä¼ é€’è¿‡æ¥çš„æ–‡æ¡£HTMLä¿¡æ¯
        Returns:
            HTMLä¿¡æ¯
        """
        response = requests.get(self.url, cookies=self.cookies, headers=self.headers)
        return response.text

    def split_link_tags(self):
        url_parts = re.split('[/\?&#]+', self.url)
        try:
            l_index = url_parts.index('l')
            otl_url_str = url_parts[l_index + 1]
            return otl_url_str
        except ValueError:
            return None

    def get_file_content(self):
        """
        çˆ¬è™«è§£æžæ–‡æ¡£å†…å®¹
        Returns:
            æ–‡æ¡£å†…å®¹
        """
        otl_url_str = self.split_link_tags()
        if otl_url_str is None: return
        html_content = self.get_file_info()
        self.bs4_file_info(html_content)  # è°ƒç”¨ bs4_file_info() æ–¹æ³•è§£æž html_contentï¼ŒèŽ·å–æ–‡ä»¶ä¿¡æ¯# æ›´æ–°ç±»çš„parm_data å’Œ headers
        json_data = json.dumps(self.parm_otl_data)
        response = requests.post(
            str(self.tol_url).replace('%v', otl_url_str),
            cookies=self.cookies,
            headers=self.headers,
            data=json_data,)
        return response.text

    def get_file_pic_url(self, pic_dict: dict):
        otl_url_str = self.split_link_tags()
        if otl_url_str is None: return
        for pic in pic_dict:
            pic_parm = {'attachment_id': pic, "imgId": pic_dict[pic], "max_edge": 1180, "source": ""}
            self.parm_shapes_data['objects'].append(pic_parm)
        json_data = json.dumps(self.parm_shapes_data)
        response = requests.post(
            str(self.shapes_url).replace('%v', otl_url_str),
            cookies=self.cookies,
            headers=self.headers,
            data=json_data,)
        url_data = response.json()['data']
        for pic in url_data:
            pic_dict[pic] = self.url_decode(url_data[pic]['url'])
        return pic_dict


    @staticmethod
    def url_decode(url):
        decoded_url = urllib.parse.unquote(url)
        return decoded_url


    def bs4_file_info(self, html_str):
        """
        bs4çˆ¬è™«æ–‡æ¡£ä¿¡æ¯ï¼Œæ²¡æœ‰è¿™ä¸ªå¯ä¸è¡ŒðŸ¤¨
        Args:
            html_str: HTMLä¿¡æ¯
        Returns:
            {'connid': æ–‡æ¡£id, 'group': æ–‡æ¡£çš„ç¾¤ç»„, 'front_ver': æ–‡æ¡£ç‰ˆæœ¬}
        """
        html = BeautifulSoup(html_str, "html.parser")
        # Find all script tags in the HTML
        script_tags = html.find_all("script")
        json_string = None
        # Iterate through script tags to find the one containing required data
        for tag in script_tags:
            if tag.string and "window.__WPSENV__" in tag.string:
                json_string = re.search(r"window\.__WPSENV__=(.*);", tag.string).group(1)
                break
        if json_string:
            # Load the JSON data from the found string
            json_data = json.loads(json_string)
            file_connid = json_data['conn_id']
            file_group = json_data['user_group']
            file_front_ver = json_data['file_version']
            self.headers['x-csrf-rand'] = json_data['csrf_token']
            self.parm_otl_data.update({'connid': file_connid, 'group': file_group, 'front_ver': file_front_ver})
            return True
        else:
            return None

def get_docs_content(url, image_processing=False):
    kdocs = Kdocs(url)
    json_data = kdocs.get_file_content()
    dict_data = json.loads(json_data)
    _all, content, pic_dict = Utils().find_all_text_keys(dict_data, filter_type='', img_proce=image_processing)
    pic_dict_convert = kdocs.get_file_pic_url(pic_dict)
    empty_picture_count = sum(1 for item in _all if 'picture' in item and not item['picture']['caption'])
    return _all, content, empty_picture_count, pic_dict_convert



def json_args_return(kwargs, keys: list) -> list: 
    temp = [False for i in range(len(keys))]
    for i in range(len(keys)):
        try:
            temp[i] = json.loads(kwargs[['advanced_arg']])[keys[i]]
        except Exception as f:
            try:
                temp[i] = kwargs['parameters_def'][keys[i]]
            except Exception as f:
                temp[i] = False
    return temp

if __name__ == '__main__':
    print(get_docs_content('https://kdocs.cn/l/ca1FQfQ6LiAx'))
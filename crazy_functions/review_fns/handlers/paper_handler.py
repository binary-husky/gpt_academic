from typing import List, Dict, Any, Optional, Tuple
from .base_handler import BaseHandler
from crazy_functions.review_fns.query_analyzer import SearchCriteria
import asyncio
from crazy_functions.crazy_utils import request_gpt_model_multi_threads_with_very_awesome_ui_and_high_efficiency as request_gpt

class å•ç¯‡è®ºæ–‡åˆ†æåŠŸèƒ½(BaseHandler):
    """è®ºæ–‡åˆ†æå¤„ç†å™¨"""

    def __init__(self, arxiv, semantic, llm_kwargs=None):
        super().__init__(arxiv, semantic, llm_kwargs)

    async def handle(
        self,
        criteria: SearchCriteria,
        chatbot: List[List[str]],
        history: List[List[str]],
        system_prompt: str,
        llm_kwargs: Dict[str, Any],
        plugin_kwargs: Dict[str, Any],
    ) -> str:
        """å¤„ç†è®ºæ–‡åˆ†æè¯·æ±‚ï¼Œè¿”å›æœ€ç»ˆçš„prompt"""

        # 1. è·å–è®ºæ–‡è¯¦æƒ…
        paper = await self._get_paper_details(criteria)
        if not paper:
            return self._generate_apology_prompt(criteria)

        # ä¿å­˜ä¸ºranked_papersä»¥ä¾¿ç»Ÿä¸€æ¥å£
        self.ranked_papers = [paper]

        # 2. æ„å»ºæœ€ç»ˆçš„prompt
        current_time = self._get_current_time()

        # è·å–è®ºæ–‡ä¿¡æ¯
        title = getattr(paper, "title", "Unknown Title")
        authors = getattr(paper, "authors", [])
        year = getattr(paper, "year", "Unknown Year")
        abstract = getattr(paper, "abstract", "No abstract available")
        citations = getattr(paper, "citations", "N/A")

        # æ·»åŠ è®ºæ–‡IDä¿¡æ¯
        paper_id = ""
        if criteria.paper_source == "arxiv":
            paper_id = f"arXiv ID: {criteria.paper_id}\n"
        elif criteria.paper_source == "doi":
            paper_id = f"DOI: {criteria.paper_id}\n"

        # æ ¼å¼åŒ–ä½œè€…åˆ—è¡¨
        authors_str = ', '.join(authors) if isinstance(authors, list) else authors

        final_prompt = f"""Current time: {current_time}

Please provide a comprehensive analysis of the following paper:

{paper_id}Title: {title}
Authors: {authors_str}
Year: {year}
Citations: {citations}
Publication Venue: {paper.venue_name} ({paper.venue_type})
{f"Publisher: {paper.venue_info.get('publisher')}" if paper.venue_info.get('publisher') else ""}
{f"Journal Reference: {paper.venue_info.get('journal_ref')}" if paper.venue_info.get('journal_ref') else ""}
Abstract: {abstract}

Please provide:
1. Publication Context
   - Publication venue analysis and impact factor (if available)
   - Paper type (journal article, conference paper, preprint)
   - Publication timeline and peer review status
   - Publisher reputation and venue prestige

2. Research Context
   - Field positioning and significance
   - Historical context and prior work
   - Related research streams
   - Cross-venue impact analysis

3. Technical Analysis
   - Detailed methodology review
   - Implementation details
   - Experimental setup and results
   - Technical innovations

4. Impact Analysis
   - Citation patterns and influence
   - Cross-venue recognition
   - Industry vs. academic impact
   - Practical applications

5. Critical Review
   - Methodological rigor assessment
   - Result reliability and reproducibility
   - Venue-appropriate evaluation standards
   - Limitations and potential improvements

IMPORTANT:
- Strictly use ONLY the information provided above about the paper
- Do not make ANY assumptions or inferences beyond the given data
- If certain information is not provided, explicitly state that it is unknown
- For any unclear or missing details, acknowledge the limitation rather than speculating
- When discussing methodology or results, only describe what is explicitly stated in the abstract
- Never fabricate or assume any details about:
  * Publication venues or status
  * Implementation details not mentioned
  * Results or findings not stated
  * Impact or influence not supported by the citation count
  * Authors' affiliations or backgrounds
  * Future work or implications not mentioned
- You can find the paper's download options in the ğŸ“¥ PDF Downloads section
- Available download formats include arXiv PDF, DOI links, and source URLs

Format your response in markdown with clear sections.

Language requirement:
- If the query explicitly specifies a language, use that language
- Otherwise, match the language of the original user query
"""

        return final_prompt

    async def _get_paper_details(self, criteria: SearchCriteria):
        """è·å–è®ºæ–‡è¯¦æƒ…"""
        try:
            if criteria.paper_source == "arxiv":
                # ä½¿ç”¨ arxiv ID æœç´¢
                papers = await self.arxiv.search_by_id(criteria.paper_id)
                return papers[0] if papers else None

            elif criteria.paper_source == "doi":
                # å°è¯•ä»æ‰€æœ‰æ¥æºè·å–
                paper = await self.semantic.get_paper_by_doi(criteria.paper_id)
                if not paper:
                    # å¦‚æœSemantic Scholaræ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•PubMed
                    papers = await self.pubmed.search(
                        f"{criteria.paper_id}[doi]",
                        limit=1
                    )
                    if papers:
                        return papers[0]
                return paper

            elif criteria.paper_source == "title":
                # ä½¿ç”¨_search_all_sourcesæœç´¢
                search_params = {
                    'max_papers': 1,
                    'min_year': 1900,  # ä¸é™åˆ¶å¹´ä»½
                    'search_multiplier': 1
                }

                # è®¾ç½®æœç´¢å‚æ•°
                criteria.arxiv_params = {
                    "search_type": "basic",
                    "query": f'ti:"{criteria.paper_title}"',
                    "limit": 1
                }
                criteria.semantic_params = {
                    "query": criteria.paper_title,
                    "limit": 1
                }
                criteria.pubmed_params = {
                    "search_type": "basic",
                    "query": f'"{criteria.paper_title}"[Title]',
                    "limit": 1
                }

                papers = await self._search_all_sources(criteria, search_params)
                return papers[0] if papers else None

            # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨ main_topic ä½œä¸ºæ ‡é¢˜æœç´¢
            if not criteria.paper_title and not criteria.paper_id:
                search_params = {
                    'max_papers': 1,
                    'min_year': 1900,
                    'search_multiplier': 1
                }

                # è®¾ç½®æœç´¢å‚æ•°
                criteria.arxiv_params = {
                    "search_type": "basic",
                    "query": f'ti:"{criteria.main_topic}"',
                    "limit": 1
                }
                criteria.semantic_params = {
                    "query": criteria.main_topic,
                    "limit": 1
                }
                criteria.pubmed_params = {
                    "search_type": "basic",
                    "query": f'"{criteria.main_topic}"[Title]',
                    "limit": 1
                }

                papers = await self._search_all_sources(criteria, search_params)
                return papers[0] if papers else None

            return None

        except Exception as e:
            print(f"è·å–è®ºæ–‡è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")
            return None

    async def _get_citation_context(self, paper: Dict, plugin_kwargs: Dict) -> Tuple[List, List]:
        """è·å–å¼•ç”¨ä¸Šä¸‹æ–‡"""
        search_params = self._get_search_params(plugin_kwargs)

        # ä½¿ç”¨è®ºæ–‡æ ‡é¢˜æ„å»ºæœç´¢å‚æ•°
        title_query = f'ti:"{getattr(paper, "title", "")}"'
        arxiv_params = {
            "query": title_query,
            "limit": search_params['max_papers'],
            "search_type": "basic",
            "sort_by": "relevance",
            "sort_order": "descending"
        }
        semantic_params = {
            "query": getattr(paper, "title", ""),
            "limit": search_params['max_papers']
        }

        citations, references = await asyncio.gather(
            self._search_semantic(
                semantic_params,
                limit_multiplier=search_params['search_multiplier'],
                min_year=search_params['min_year']
            ),
            self._search_arxiv(
                arxiv_params,
                limit_multiplier=search_params['search_multiplier'],
                min_year=search_params['min_year']
            )
        )

        return citations, references

    async def _generate_analysis(
        self,
        paper: Dict,
        citations: List,
        references: List,
        chatbot: List[List[str]],
        history: List[List[str]],
        system_prompt: str,
        llm_kwargs: Dict[str, Any]
    ) -> List[List[str]]:
        """ç”Ÿæˆè®ºæ–‡åˆ†æ"""

        # æ„å»ºæç¤º
        analysis_prompt = f"""Please provide a comprehensive analysis of the following paper:

Paper details:
{self._format_paper(paper)}

Key references (papers cited by this paper):
{self._format_papers(references)}

Important citations (papers that cite this paper):
{self._format_papers(citations)}

Please provide:
1. Paper Overview
   - Main research question/objective
   - Key methodology/approach
   - Main findings/contributions

2. Technical Analysis
   - Detailed methodology review
   - Technical innovations
   - Implementation details
   - Experimental setup and results

3. Impact Analysis
   - Significance in the field
   - Influence on subsequent research (based on citing papers)
   - Relationship to prior work (based on cited papers)
   - Practical applications

4. Critical Review
   - Strengths and limitations
   - Potential improvements
   - Open questions and future directions
   - Alternative approaches

5. Related Research Context
   - How it builds on previous work
   - How it has influenced subsequent research
   - Comparison with alternative approaches

Format your response in markdown with clear sections."""

        # å¹¶è¡Œç”Ÿæˆæ¦‚è¿°å’ŒæŠ€æœ¯åˆ†æ
        for response_chunk in request_gpt(
            inputs_array=[
                analysis_prompt,
                self._get_technical_prompt(paper)
            ],
            inputs_show_user_array=[
                "Generating paper analysis...",
                "Analyzing technical details..."
            ],
            llm_kwargs=llm_kwargs,
            chatbot=chatbot,
            history_array=[history, []],
            sys_prompt_array=[
                system_prompt,
                "You are an expert at analyzing technical details in research papers."
            ]
        ):
            pass  # ç­‰å¾…ç”Ÿæˆå®Œæˆ

        # è·å–æœ€åçš„ä¸¤ä¸ªå›ç­”
        if chatbot and len(chatbot[-2:]) == 2:
            analysis = chatbot[-2][1]
            technical = chatbot[-1][1]
            full_analysis = f"""# Paper Analysis: {paper.title}

## General Analysis
{analysis}

## Technical Deep Dive
{technical}
"""
            chatbot.append(["Here is the paper analysis:", full_analysis])
        else:
            chatbot.append(["Here is the paper analysis:", "Failed to generate analysis."])

        return chatbot

    def _get_technical_prompt(self, paper: Dict) -> str:
        """ç”ŸæˆæŠ€æœ¯åˆ†ææç¤º"""
        return f"""Please provide a detailed technical analysis of the following paper:

{self._format_paper(paper)}

Focus on:
1. Mathematical formulations and their implications
2. Algorithm design and complexity analysis
3. Architecture details and design choices
4. Implementation challenges and solutions
5. Performance analysis and bottlenecks
6. Technical limitations and potential improvements

Format your response in markdown, focusing purely on technical aspects."""



# encoding: utf-8
# @Time   : 2023/9/2
# @Author : Spike
# @Descr   :
import json
import os, random
import copy
import re
import tempfile
import time
import uuid
from typing import List

import gradio as gr
import pandas as pd

import yaml
from yarl import URL

from common import toolbox
from common import db_handler
from common import func_box
from common import history_handler
from common.path_handler import init_path
from common.logger_handler import logger

# å¤„ç†latex options
latex_delimiters_dict = {
    'default': [
        {"left": "$$", "right": "$$", "display": True},
        {"left": "$", "right": "$", "display": False},
        {"left": "\\(", "right": "\\)", "display": False},
        {"left": "\\[", "right": "\\]", "display": True},
    ],
    'strict': [
        {"left": "$$", "right": "$$", "display": True},
        {"left": "\\(", "right": "\\)", "display": False},
        {"left": "\\[", "right": "\\]", "display": True},
    ],
    'all': [
        {"left": "$$", "right": "$$", "display": True},
        {"left": "$", "right": "$", "display": False},
        {"left": "\\(", "right": "\\)", "display": False},
        {"left": "\\[", "right": "\\]", "display": True},
        {"left": "\\begin{equation}", "right": "\\end{equation}", "display": True},
        {"left": "\\begin{align}", "right": "\\end{align}", "display": True},
        {"left": "\\begin{alignat}", "right": "\\end{alignat}", "display": True},
        {"left": "\\begin{gather}", "right": "\\end{gather}", "display": True},
        {"left": "\\begin{CD}", "right": "\\end{CD}", "display": True},
    ],
    'disabled': [],
    'else': [
        {"left": "$$", "right": "$$", "display": True},
        {"left": "$", "right": "$", "display": False},
        {"left": "\\(", "right": "\\)", "display": False},
        {"left": "\\[", "right": "\\]", "display": True},
    ]

}


def spinner_chatbot_loading(chatbot):
    loading = [''.join(['.' * random.randint(1, 5)])]
    # å°†å…ƒç»„è½¬æ¢ä¸ºåˆ—è¡¨å¹¶ä¿®æ”¹å…ƒç´ 
    loading_msg = copy.deepcopy(chatbot)
    temp_list = list(loading_msg[-1])

    temp_list[1] = func_box.pattern_html(temp_list[1]) + f'{random.choice(loading)}'
    # å°†åˆ—è¡¨è½¬æ¢å›å…ƒç»„å¹¶æ›¿æ¢åŸå§‹å…ƒç»„
    loading_msg[-1] = tuple(temp_list)
    return loading_msg


def get_database_cls(t):
    return "_".join(str(t).split('_')[0:-1])


def filter_database_tables():
    tables = db_handler.PromptDb(None).get_tables()
    split_tab = []
    for t in tables:
        if str(t).endswith('_sys'):
            split_tab.append(get_database_cls(t))
    split_tab_new = split_tab
    return split_tab_new


# TODO < -------------------------------- å¼¹çª—æ•°æ³¨å†ŒåŒº ----------------------------------->
def on_theme_dropdown_changed(theme, ):
    from webui_elem.theme import load_dynamic_theme
    adjust_theme, adjust_dynamic_theme = load_dynamic_theme(theme)
    if adjust_dynamic_theme:
        try:
            css_part2 = adjust_dynamic_theme._get_theme_css()
        except:
            raise
    else:
        css_part2 = adjust_theme._get_theme_css()
    return css_part2, gr.update()


def switch_latex_output(select):
    if select not in list(latex_delimiters_dict):
        latex = latex_delimiters_dict['else']
    else:
        latex = latex_delimiters_dict[select]
    return gr.update(latex_delimiters=latex)


# TODO < -------------------------------- å¯¹è¯å‡½æ•°æ³¨å†ŒåŒº ----------------------------------->
def update_chat(llm_s):
    return gr.update(avatar_images=func_box.get_avatar_img(llm_s))


def sm_upload_clear(cookie: dict):
    upload_ho = cookie.get('most_recent_uploaded')
    if upload_ho:
        cookie.pop('most_recent_uploaded')
    return gr.update(value=None), cookie


def clear_input(inputs, cookies, ipaddr: gr.Request):
    user_addr = func_box.user_client_mark(ipaddr)
    user_path = os.path.join(init_path.private_history_path, user_addr)
    file_list, only_name, new_path, new_name = func_box.get_files_list(user_path, filter_format=['.json'])
    index = 2
    if not cookies.get('first_chat'):
        cookies['first_chat'] = func_box.replace_special_chars(str(inputs)[:25])
        select_file = cookies.get('first_chat')
        while select_file in only_name:  # é‡åå¤„ç†
            select_file = f"{index}_{cookies['first_chat']}"
            index += 1
        cookies['first_chat'] = select_file
        only_name = [cookies['first_chat']] + only_name
        # å…ˆå†™å…¥ä¸€ä¸ªç©ºæ–‡ä»¶å ä½
        with open(os.path.join(user_path, cookies['first_chat'] + ".json"), mode='w') as f:
            f.write('{}')
    output = [gr.update(value=''), inputs, gr.update(visible=True), gr.update(), gr.update(visible=False),
              gr.update(choices=only_name, value=cookies['first_chat']), gr.update(value=None)]
    yield output
    logger.info(f"{cookies['llm_model']}_{user_addr}: {inputs[:100]} {'.' * 10}")


def stop_chat_refresh(chatbot, cookies, ipaddr: gr.Request):
    if isinstance(ipaddr, gr.Request):
        user = func_box.user_client_mark(ipaddr)
    else:
        user = ipaddr
    chatbot_with_cookie = toolbox.ChatBotWithCookies(cookies)
    chatbot_with_cookie.write_list(chatbot)
    # user_path = os.path.join(init_path.private_history_path, ipaddr.client.host)
    history_handler.thread_write_chat_json(chatbot_with_cookie, user)


def clear_chat_cookie(llm_model, ipaddr: gr.Request):
    API_KEY = toolbox.get_conf('API_KEY')
    cookie = {'api_key': API_KEY, 'llm_model': llm_model}
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    file_list, only_name, new_path, new_name = func_box.get_files_list(user_path, filter_format=['.json'])
    default_params = toolbox.get_conf('LLM_DEFAULT_PARAMETER')
    llms_combo = [cookie.get(key, default_params[key]) for key in default_params] + [
        gr.update(value=llm_model)]
    output = [[], [], cookie, *llms_combo, 'å·²é‡ç½®å¯¹è¯è®°å½•å’Œå¯¹è¯Cookies',
              gr.update(choices=['æ–°å¯¹è¯'] + only_name, value='æ–°å¯¹è¯'), "æ–°å¯¹è¯"]
    return output


def select_history(select, llm_select, cookies, ipaddr: gr.Request):
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    user_history = [f for f in os.listdir(user_path) if f.endswith('.json') and select == os.path.splitext(f)[0]]
    if not user_history:
        default_params, API_KEY = toolbox.get_conf('LLM_DEFAULT_PARAMETER', 'API_KEY')
        llms_combo = [cookies.get(key, default_params[key]) for key in default_params]
        cookies = {'api_key': API_KEY}
        return [[], [], cookies, *llms_combo, llm_select, select]
    file_path = os.path.join(user_path, user_history[0])
    history_handle = history_handler.HistoryJsonHandle(file_path)
    history_update_combo = history_handle.update_for_history(cookies, select)
    return [*history_update_combo, select, gr.update(link=func_box.html_local_file(file_path))]


def rename_history(old_file, filename: str, ipaddr: gr.Request):
    filename = filename.strip(' \n')
    if filename == "":
        return gr.update()
    if not filename.endswith(".json"):
        filename += ".json"
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    full_path = os.path.join(user_path, filename)
    if not os.path.exists(os.path.join(user_path, f"{old_file}.json")):
        return gr.Error(f'{old_file}å†å²æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·åˆ·æ–°é¡µé¢åå°è¯•')
    repeat_file_index = 2
    while os.path.exists(full_path):  # å‘½åé‡å¤æ£€æµ‹
        full_path = os.path.join(user_path, f"{repeat_file_index}_{filename}")
        repeat_file_index += 1
    os.rename(os.path.join(user_path, f"{old_file}.json"), full_path)
    file_list, only_name, new_path, new_name = func_box.get_files_list(user_path, filter_format=['.json'])
    return gr.update(choices=only_name, value=new_name)


def delete_history(cookies, filename, info, ipaddr: gr.Request):
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    full_path = os.path.join(user_path, f"{filename}.json")
    if not os.path.exists(full_path):
        if filename == 'CANCELED':
            return [gr.update() for i in range(16)]
        else:
            raise gr.Error('æ–‡ä»¶æˆ–è®¸å·²ä¸å­˜åœ¨')
    os.remove(full_path)
    file_list, only_name, new_path, new_name = func_box.get_files_list(
        os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr)), filter_format=['.json'])
    history_handle = history_handler.HistoryJsonHandle(new_path)
    history_update_combo = history_handle.update_for_history(cookies, new_name)
    return [gr.update(choices=only_name, value=new_name), *history_update_combo]


def import_history(file, ipaddr: gr.Request):
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    index = 2
    new_file = os.path.basename(file.name)
    while new_file in os.listdir(user_path):
        new_file = f'{index}_{os.path.basename(file.name)}'
        index += 1
    os.rename(file.name, os.path.join(user_path, new_file))
    file_list, only_name, new_path, new_name = func_box.get_files_list(user_path, filter_format=['.json'])
    return gr.update(choices=only_name, value=new_name)


def refresh_history(cookies, ipaddr: gr.Request):
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    file_list, only_name, new_path, new_name = func_box.get_files_list(user_path, filter_format=['.json'])
    history_handle = history_handler.HistoryJsonHandle(new_path)
    history_update_combo = history_handle.update_for_history(cookies, new_name)
    return [gr.update(choices=only_name, value=new_name), *history_update_combo]


def download_history_json(select, ipaddr: gr.Request):
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    file_path = os.path.join(user_path, f"{select}.json")
    if not os.path.exists(file_path):
        raise gr.Error('å½“å‰å¯¹è¯è®°å½•ç©ºï¼Œå¯¼å‡ºå¤±è´¥')
    link = func_box.link_mtime_to_md(file_path)
    return f'ä¸‹è½½é“¾æ¥:{link}ï¼Œ å¯¹è¯è®°å½•å¯¼å‡ºjsonæˆåŠŸ'


def download_history_md(select, ipaddr: gr.Request):
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    file_path = os.path.join(user_path, f"{select}.json")
    if not os.path.exists(file_path):
        raise gr.Error('å½“å‰å¯¹è¯è®°å½•ç©ºï¼Œå¯¼å‡ºå¤±è´¥')
    history_handle = history_handler.HistoryJsonHandle(file_path)
    history_list = history_handle.base_data_format['chat']
    system = history_handle.base_data_format['chat_llms'].get('system_prompt').replace('\n', '\n> ')
    mark_down = f"> {func_box.html_tag_color(tag='System Prompt:', color='#ff6e67')} {system}\n\n"
    for i in history_list:
        chat = i.get('on_chat', ["", ""])
        user, bot = str(chat[0]).replace('\n', '\n> '), str(chat[1]).replace('\n', '\n> ')
        mark_down += f"> {func_box.html_tag_color(tag='User:', color='#3e9855')} \n{user}\n\n"
        mark_down += f"> {func_box.html_tag_color(tag='Bot:', color='#bc8af4')} \n{bot}\n\n"
    mark_down += f"```json\n# å¯¹è¯è°ƒä¼˜å‚æ•°\n{history_handle.base_data_format['chat_llms']}\n```"
    is_plugin = history_list[-1].get('plugin')
    if is_plugin:
        mark_down += f"```json\n# æ’ä»¶è°ƒä¼˜å‚æ•°\n{is_plugin}\n```"
    file_path = os.path.join(user_path, f'{select}.md')
    with open(file=file_path, mode='w') as f:
        f.write(mark_down)
    link = func_box.link_mtime_to_md(file_path)
    return f'ä¸‹è½½é“¾æ¥:{link}, å¯¹è¯è®°å½•è½¬æ¢ä¸ºmarkdownæˆåŠŸ'


def converter_history_masks(chatbot, system_prompt, ipaddr: gr.Request):
    mask_dataset = [['system', system_prompt]]
    for i in chatbot:
        mask_dataset.append(['user', func_box.match_chat_information(i[0])])
        mask_dataset.append(['assistant', func_box.match_chat_information(i[1])])
    return gr.update(value=mask_dataset)


# TODO < -------------------------------- å°æŒ‰é’®å‡½æ•°æ³¨å†ŒåŒº -------------------------------->
def delete_latest_chat(chatbot, history, cookies: dict, ipaddr: gr.Request):
    select = cookies.get('first_chat', '')
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr), f"{select}.json")
    history_handle = history_handler.HistoryJsonHandle(user_path)
    history_handle.delete_the_latest_chat()
    history_update_combo = history_handle.update_for_history(cookies, select)
    return history_update_combo


def get_user_upload(chatbot, txt, ipaddr: gr.Request):
    """
    è·å–ç”¨æˆ·ä¸Šä¼ è¿‡çš„æ–‡ä»¶
    """
    private_upload = init_path.private_files_path.replace(init_path.base_path, '.')
    user_history = os.path.join(private_upload, func_box.user_client_mark(ipaddr))
    history = """| ç¼–å· | ç›®å½• | ç›®å½•å†…æ–‡ä»¶ |\n| --- | --- | --- |\n"""
    count_num = 1
    for root, d, file in os.walk(user_history):
        if txt in str(file) or txt in root:
            file_link = "<br>".join([f'{func_box.html_view_blank(f"{root}/{i}")}' for i in file])
            history += f'| {count_num} | {root} | {file_link} |\n'
            count_num += 1
    chatbot.append([None,  # 'Load Submission History like `{txt}`....',
                    f'{history}\n\n'
                    f'[Local Message] è¯·è‡ªè¡Œå¤åˆ¶ä»¥ä¸Šç›®å½• or ç›®å½•+æ–‡ä»¶, å¡«å…¥è¾“å…¥æ¡†ä»¥ä¾›å‡½æ•°åŒºé«˜äº®æŒ‰é’®ä½¿ç”¨\n\n'
                    f'{func_box.html_tag_color("æäº¤å‰è®°å¾—è¯·æ£€æŸ¥å¤´å°¾ç©ºæ ¼å“¦ï½")}\n\n'])
    return chatbot


# TODO < -------------------------------- åŸºç¡€åŠŸèƒ½å‡½æ•°æ³¨å†ŒåŒº -------------------------------->
def prompt_retrieval(prompt_cls, hosts, search=False):
    """
    ä¸Šä¼ æ–‡ä»¶ï¼Œå°†æ–‡ä»¶è½¬æ¢ä¸ºå­—å…¸ï¼Œç„¶åå­˜å‚¨åˆ°æ•°æ®åº“ï¼Œå¹¶åˆ·æ–°PromptåŒºåŸŸ
    Args:
        is_allï¼š promptç±»å‹
        hostsï¼š æŸ¥è¯¢çš„ç”¨æˆ·ip
    Returns:
        è¿”å›ä¸€ä¸ªåˆ—è¡¨
    """
    all_, personal = toolbox.get_conf('preset_prompt')['key']
    if not prompt_cls: prompt_cls = all_  # ä¿åº•
    count_dict = {}
    hosts_tabs = func_box.prompt_personal_tag(prompt_cls, hosts)
    if all_ == prompt_cls:
        for tab in db_handler.PromptDb(None).get_tables():
            if str(tab).endswith('sys'):
                data, source = db_handler.PromptDb(tab).get_prompt_value(None)
                if data: count_dict.update({get_database_cls(tab): data})
        data, source = db_handler.PromptDb(f'{hosts_tabs}').get_prompt_value(None)
        if data: count_dict.update({personal: data})
    elif personal == prompt_cls:
        data, source = db_handler.PromptDb(f'{hosts_tabs}').get_prompt_value(None)
        if data: count_dict.update({personal: data})
    elif hosts_tabs and prompt_cls:
        data, source = db_handler.PromptDb(f'{hosts_tabs}').get_prompt_value(None)
        if data: count_dict.update({prompt_cls: data})
    retrieval = []
    if count_dict != {}:  # ä¸Šé¢æ˜¯ä¸€æ®µå±å±±ï¼Œ ä¸çŸ¥é“è‡ªå·±ä¸ºä»€ä¹ˆè¦è¿™æ ·å†™ï¼Œåæ­£èƒ½ç”¨
        for cls in count_dict:
            for key in count_dict[cls]:
                content = count_dict[cls][key]
                if func_box.check_list_format(content):
                    show_key = f'ğŸ­ ' + key
                else:
                    show_key = key
                retrieval.append([show_key, key, content, cls])
        retrieval.reverse()
        return retrieval
    else:
        return retrieval


def change_check_txt(checkbox, prompt):
    if checkbox:
        return gr.update(label='Prompt - å¤ç”¨', samples=prompt['samples'], visible=True)
    else:
        return gr.update(label='Prompt - ç¼–è¾‘', samples=prompt['samples'], visible=True)


def prompt_reduce(is_all, prompt: gr.Dataset, ipaddr: gr.Request):  # is_all, ipaddr: gr.Request
    """
    åˆ·æ–°æç¤ºè¯
    Args:
        is_allï¼š promptç±»å‹
        promptï¼š datasetåŸå§‹å¯¹è±¡
        ipaddrï¼šè¯·æ±‚ç”¨æˆ·ä¿¡æ¯
    Returns:
        è¿”å›æ³¨å†Œå‡½æ•°æ‰€éœ€çš„å¯¹è±¡
    """
    data = prompt_retrieval(prompt_cls=is_all, hosts=func_box.user_client_mark(ipaddr))
    prompt['samples'] = data
    return gr.update(samples=data, visible=True), prompt, is_all


def prompt_upload_refresh(file, prompt, pro_select, ipaddr: gr.Request):
    """
    ä¸Šä¼ æ–‡ä»¶ï¼Œå°†æ–‡ä»¶è½¬æ¢ä¸ºå­—å…¸ï¼Œç„¶åå­˜å‚¨åˆ°æ•°æ®åº“ï¼Œå¹¶åˆ·æ–°PromptåŒºåŸŸ
    Args:
        fileï¼š ä¸Šä¼ çš„æ–‡ä»¶
        promptï¼š åŸå§‹promptå¯¹è±¡
        ipaddrï¼šipaddrç”¨æˆ·è¯·æ±‚ä¿¡æ¯
    Returns:
        æ³¨å†Œå‡½æ•°æ‰€éœ€çš„å…ƒç¥–å¯¹è±¡
    """
    user_info = func_box.user_client_mark(ipaddr)
    tab_cls = func_box.prompt_personal_tag(pro_select, func_box.user_client_mark(ipaddr))
    if file.name.endswith('json'):
        upload_data = func_box.check_json_format(file.name)
    elif file.name.endswith('yaml'):
        upload_data = yaml.safe_load(file.file)
    else:
        upload_data = {}
    if upload_data != {}:
        status = db_handler.PromptDb(f'{tab_cls}').inset_prompt(upload_data, user_info)
        ret_data = prompt_retrieval(prompt_cls=tab_cls, hosts=func_box.user_client_mark(ipaddr))
        return gr.update(samples=ret_data, visible=True), prompt, tab_cls
    else:
        prompt['samples'] = [
            [f'{func_box.html_tag_color("æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç¬¦åˆè§„èŒƒ", color="red")}', tab_cls]]
        return prompt['samples'], prompt, []


def prompt_delete(pro_name, prompt_dict, select_check, ipaddr: gr.Request):
    user_addr = func_box.user_client_mark(ipaddr)
    if not pro_name:
        raise gr.Error('åˆ é™¤åç§°ä¸èƒ½ä¸ºç©º')
    find_prompt = [i for i in prompt_dict['samples'] if i[1] == pro_name]
    if not any(find_prompt):
        raise gr.Error(f'æ— æ³•æ‰¾åˆ° {pro_name}')
    tab_cls = func_box.prompt_personal_tag(select_check, user_addr)
    sqlite_handle = db_handler.PromptDb(table=f'{tab_cls}')
    _, source = sqlite_handle.get_prompt_value(find=pro_name)
    if not _:
        raise gr.Error(f'æ— æ³•æ‰¾åˆ° {pro_name}ï¼Œæˆ–è¯·ä¸è¦åœ¨æ‰€æœ‰äººåˆ†ç±»ä¸‹åˆ é™¤')
    if str(source) in user_addr or '127.0.0.1' == user_addr or 'spike' == user_addr:
        sqlite_handle.delete_prompt(pro_name)
    else:
        raise gr.Error(f'æ— æ³•åˆ é™¤ä¸å±äºä½ åˆ›å»ºçš„ {pro_name}ï¼Œå¦‚æœ‰ç´§æ€¥éœ€æ±‚ï¼Œè¯·è”ç³»ç®¡ç†å‘˜')
    data = prompt_retrieval(prompt_cls=None, hosts=user_addr)
    prompt_dict['samples'] = data
    toast = gr.update(value=func_box.spike_toast(f'`{pro_name}` åˆ é™¤æˆåŠŸ'), visible=True)
    yield gr.update(samples=data, visible=True), prompt_dict, toast
    time.sleep(1)
    yield gr.update(samples=data, visible=True), prompt_dict, gr.update(visible=False)


def prompt_save(txt, name, prompt: gr.Dataset, pro_select, ipaddr: gr.Request):
    """
    ç¼–è¾‘å’Œä¿å­˜Prompt
    Args:
        txtï¼š Promptæ­£æ–‡
        nameï¼š Promptçš„åå­—
        promptï¼š datasetåŸå§‹å¯¹è±¡
        ipaddrï¼šè¯·æ±‚ç”¨æˆ·ä¿¡æ¯
    Returns:
        è¿”å›æ³¨å†Œå‡½æ•°æ‰€éœ€çš„å¯¹è±¡
    """
    if not pro_select:
        raise gr.Error('ä¿å­˜åˆ†ç±»ä¸èƒ½ä¸ºç©º ï¼')
    user_info = func_box.user_client_mark(ipaddr)
    tab_cls = func_box.prompt_personal_tag(pro_select, func_box.user_client_mark(ipaddr))
    if txt and name:
        sql_obj = db_handler.PromptDb(f'{tab_cls}')
        _, source = sql_obj.get_prompt_value(name)
        status = sql_obj.inset_prompt({name: txt}, user_info)
        if status:
            raise gr.Error('!!!!å·²æœ‰å…¶ä»–äººä¿å­˜åŒåçš„é…ç½®ï¼Œè¯·ä¿®æ”¹å   ç§°åå†ä¿å­˜')
        else:
            result = prompt_retrieval(prompt_cls=pro_select, hosts=func_box.user_client_mark(ipaddr))
            prompt['samples'] = result
            toast = gr.update(value=func_box.spike_toast(f'`{name}` ä¿å­˜æˆåŠŸ'), visible=True)
            yield gr.update(samples=result, visible=True), prompt, toast
            time.sleep(1)
            yield gr.update(samples=result, visible=True), prompt, gr.update(visible=False)
    elif not txt or not name:
        raise gr.Error('!!!!ç¼–è¾‘åŒºåŸŸ or åç§°ä¸èƒ½ä¸ºç©º!!!!')


def prompt_input(edit_check, input_txt: str, llm_select, index, data, ipaddr: gr.Request):
    """
    ç‚¹å‡»datasetçš„å€¼ä½¿ç”¨Prompt
    Args:
        txtï¼š è¾“å…¥æ¡†æ­£æ–‡
        indexï¼š ç‚¹å‡»çš„Datasetä¸‹æ ‡
        dataï¼š datasetåŸå§‹å¯¹è±¡
    Returns:
        è¿”å›æ³¨å†Œå‡½æ•°æ‰€éœ€çš„å¯¹è±¡
    """
    data_name = str(data['samples'][index][1])
    data_str = str(data['samples'][index][2])
    data_cls = str(data['samples'][index][3])
    mask_ = func_box.check_list_format(data_str)
    chatbot_cookie = clear_chat_cookie(llm_model=llm_select, ipaddr=ipaddr)
    mask_comb = [gr.update() for i in range(3)]
    prompt_comb = [gr.update() for i in range(3)]
    tab_select = gr.update()
    if edit_check:
        if mask_:
            _item, chatbot_cookie[0], chatbot_cookie[1] = mask_to_chatbot(mask_)
            chatbot_cookie[-5] = _item[0][1]  # system
            chatbot_cookie[2].update({'first_chat': data_name})
        else:
            chatbot_cookie = [gr.update() for i in chatbot_cookie]
            if data_str.find('{{{v}}}') != -1:
                input_txt = data_str.replace('{{{v}}}', input_txt)
            else:
                input_txt = input_txt + data_str
    else:
        chatbot_cookie = [gr.update() for i in chatbot_cookie]
        if mask_:
            tab_select = gr.update(selected='masks')
            mask_comb = [data_cls, mask_, data_name]
        else:
            tab_select = gr.update(selected='prompt')
            prompt_comb = [data_cls, data_str, data_name]
    all_comb = [tab_select] + prompt_comb + mask_comb + chatbot_cookie + [input_txt]

    return all_comb


def prompt_search(tab_cls, sear_txt, sp, data_base, ipaddr: gr.Request):
    sorted_dict = prompt_retrieval(prompt_cls=tab_cls, hosts=func_box.user_client_mark(ipaddr))
    search_result = search_highlight(sorted_dict, sear_txt, False, [0, 2, 3], sp)
    data_base['samples'] = search_result
    return gr.update(samples=search_result, visible=True), data_base


def show_prompt_result(index, data: gr.Dataset, cookies, ipaddr: gr.Request):
    """
    æŸ¥çœ‹Promptçš„å¯¹è¯è®°å½•ç»“æœ
    Args:
        indexï¼š ç‚¹å‡»çš„Datasetä¸‹æ ‡
        dataï¼š datasetåŸå§‹å¯¹è±¡
        chatbotï¼šèŠå¤©æœºå™¨äºº
    Returns:
        è¿”å›æ³¨å†Œå‡½æ•°æ‰€éœ€çš„å¯¹è±¡
    """
    click = data['samples'][index]
    file_name = click[2]
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    history_handle = history_handler.HistoryJsonHandle(os.path.join(user_path, file_name + ".json"))
    cookie_combo = history_handle.update_for_history(cookies, file_name)
    return gr.update(value=file_name), *cookie_combo


# TODO < -------------------------------- æœç´¢å‡½æ•°æ³¨å†ŒåŒº -------------------------------->
def search_highlight(sorted_dict, txt, source, keyword: list, sp):
    dateset_list = []
    for key in sorted_dict:
        # å¼€å§‹åŒ¹é…å…³é”®å­—
        index = str(key[keyword[0]]).lower().find(txt.lower())
        index_ = str(key[keyword[1]]).lower().find(txt.lower())
        if index != -1 or index_ != -1:
            if index == -1: index = index_  # å¢åŠ æœç´¢prompt åç§°
            # sp=split ç”¨äºåˆ¤æ–­åœ¨å“ªé‡Œå¯åŠ¨ã€åœ¨å“ªé‡Œæ–­å¼€
            if index - sp > 0:
                start = index - sp
            else:
                start = 0
            if len(key[0]) > sp * 2:
                end = key[0][-sp:]
            else:
                end = ''
            # åˆ¤æ–­æœ‰æ²¡æœ‰ä¼ éœ€è¦åŒ¹é…çš„å­—ç¬¦ä¸²ï¼Œæœ‰åˆ™ç­›é€‰ã€æ— åˆ™å…¨è¿”
            if txt == '' and len(key[0]) >= sp:
                show = key[0][0:sp] + " . . . " + end
                show = show.replace('<', '')
            elif txt == '' and len(key[0]) < sp:
                show = key[0][0:sp]
                show = show.replace('<', '')
            else:
                show = str(key[0][start:index + sp]).replace('<', '').replace(txt, func_box.html_tag_color(txt))
            if source:
                show += f"  {func_box.html_tag_color(' in ' + str(key[1]))}"
            if not show: show = key[keyword[0]]
            dateset_list.append([show, key[keyword[0]], key[keyword[1]], key[keyword[2]]])
    return dateset_list


def reuse_chat(result, chatbot, history, say):
    """å¤ç”¨å¯¹è¯è®°å½•"""
    if result is None or result == []:
        return chatbot, history, gr.update(), gr.update()
    else:
        chatbot += result
        history += [func_box.pattern_html(_) for i in result for _ in i]
        return chatbot, history, say


def draw_results(txt, prompt: dict, percent, ipaddr: gr.Request):
    """
    ç»˜åˆ¶æœç´¢ç»“æœ
    Args:
        txt (str): è¿‡æ»¤æ–‡æœ¬
        prompt : åŸå§‹çš„datasetå¯¹è±¡
        percent (int): æœ€å¤§æ˜¾ç¤ºæ–‡æœ¬
        ipaddr : è¯·æ±‚äººä¿¡æ¯
    Returns:
        æ³¨å†Œå‡½æ•°æ‰€éœ€çš„å…ƒç¥–å¯¹è±¡
    """
    lst = {}
    file_list, only_name, new_path, new_name = func_box.get_files_list(
        os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr)), filter_format=['.json'])
    for i in file_list:
        chat_list = history_handler.HistoryJsonHandle(i).base_data_format.get('chat')
        file_name = os.path.splitext(os.path.basename(i))[0]
        chat_str = ''.join([u for k in chat_list for u in k['on_chat'] if u is not None])
        lst.update({chat_str: file_name})
    sorted_dict = sorted(lst.items(), key=lambda x: x[1], reverse=True)
    search_result = search_highlight(sorted_dict, txt, True, [0, 1, 0], percent)
    prompt['samples'] = search_result
    return gr.update(samples=search_result, visible=True), prompt


# TODO < -------------------------------- é¢å…·ç¼–è¾‘å‡½æ•°æ³¨å†ŒåŒº -------------------------------->
def mask_to_chatbot(data):
    population = []
    history = []
    chatbot = []
    for i, item in enumerate(data):
        if i == 0:
            item[0] = 'system'
        elif i % 2 == 0:
            item[0] = 'assistant'
            history.append(item[1])
        else:
            item[0] = 'user'
            history.append(item[1])
        population.append(item)
    for you, bot in zip(history[0::2], history[1::2]):
        if not you: you = None
        if not bot: bot = None
        chatbot.append([you, bot])
    return population, chatbot, history


def mask_setting_role(data):
    """
    Args:
        data: ä¸ºæ¯è¡Œæ•°æ®é¢„è®¾ä¸€ä¸ªè§’è‰²
    Returns:
    """
    setting_set, zip_chat, _ = mask_to_chatbot(data)
    return setting_set, zip_chat


def mask_del_new_row(data):
    if len(data) == 1:
        return [['system', '']]
    if data:
        return data[:-1]
    else:
        return data


def mask_clear_all(data, state, info):
    if state == 'CANCELED':
        return data
    else:
        return [['system', '']]


def reader_analysis_output(file: gr.File, choice, ipaddr: gr.Request):
    from crazy_functions.reader_fns.crazy_box import file_reader_content
    user_mark = func_box.user_client_mark(ipaddr)
    save_path = os.path.join(init_path.private_files_path, user_mark, 'reader')
    content, status = file_reader_content(file_path=file.name, save_path=save_path, plugin_kwargs={})
    if isinstance(content, list):
        content = func_box.to_markdown_tabs(head=content[0], tabs=content[1:], column=True)
    tokens = func_box.num_tokens_from_string([content])

    toast = gr.update(value=func_box.spike_toast(content=f'Submitting a dialog is expected to consume: `{tokens}`',
                                                 title='Completed'), visible=True)
    yield content, gr.Textbox.update(label=f'{tokens} Token', value=content), toast
    time.sleep(2)
    yield content, gr.Textbox.update(label=f'{tokens} Token', value=content), gr.update(visible=False)


# TODO < -------------------------------- é¡µé¢åˆ·æ–°å‡½æ•°æ³¨å†ŒåŒº -------------------------------->
def mobile_access(request: gr.Request):  # ä¸ºé€‚é…æ‰‹æœºç«¯
    user_agent = request.kwargs['headers']['user-agent'].lower()
    if user_agent.find('android') != -1 or user_agent.find('iphone') != -1:
        return gr.update(visible=False), gr.Dropdown.update(show_label=False)
    else:
        return gr.update(), gr.update()


def refresh_load_data(prompt, request: gr.Request):
    """
    Args:
        prompt: prompt datasetç»„ä»¶
    Returns:
        é¢„æœŸæ˜¯æ¯æ¬¡åˆ·æ–°é¡µé¢ï¼ŒåŠ è½½æœ€æ–°æ•°æ®
    """
    user_addr = func_box.user_client_mark(request)
    preset_prompt = toolbox.get_conf('preset_prompt')
    all = preset_prompt['key']
    is_all = preset_prompt['value']
    data = prompt_retrieval(prompt_cls=is_all, hosts=user_addr)
    prompt['samples'] = data

    kb_details_tm = base.kb_details_to_dict()
    kb_list = base.kb_dict_to_list(kb_details_tm)
    know_list = gr.update(choices=kb_list + ['æ–°å»ºçŸ¥è¯†åº“'], show_label=True)
    know_load = gr.update(choices=list(kb_details_tm.keys()), label='çŸ¥è¯†åº“', show_label=True)

    select_list = filter_database_tables()
    favicon_appname = func_box.favicon_ascii()
    outputs = [gr.update(samples=data, visible=True), prompt, favicon_appname,
               gr.update(choices=all + select_list), gr.update(choices=[all[1]] + select_list),
               gr.update(choices=[all[1]] + select_list),
               know_list, know_load]
    return outputs


def refresh_user_data(cookies, proxy_info, ipaddr: gr.Request):
    user_path = os.path.join(init_path.private_history_path, func_box.user_client_mark(ipaddr))
    file_list, only_name, new_path, new_name = func_box.get_files_list(user_path, filter_format=['.json'])
    history_handle = history_handler.HistoryJsonHandle(new_path)
    history_update_combo = history_handle.update_for_history(cookies, new_name)
    outputs = [gr.update(choices=only_name, value=new_name, visible=True), *history_update_combo,
               new_name, gr.update(value=f"ä½ å¥½ï¼Œ`{func_box.user_client_mark(ipaddr)}` {proxy_info}")]
    return outputs


# TODO < -------------------------------- é¡µé¢ç™»é™†å‡½æ•°æ³¨å†ŒåŒº -------------------------------->
def user_login(user, password):
    sql_handle = db_handler.UserDb()
    user_account = sql_handle.get_user_account(user)
    if user_account.get('user'):
        if user == user_account['user'] and password == user_account['password']:
            return True
        else:
            return False
    else:
        sql_handle.update_user(user, password)
        return True


# TODO < -------------------------------- çŸ¥è¯†åº“å‡½æ•°æ³¨å†ŒåŒº -------------------------------------->
from common.knowledge_base.kb_service import base
from common.knowledge_base import kb_doc_api, kb_api
from common.configs import kb_config
from crazy_functions.reader_fns.crazy_box import detach_cloud_links


def kb_select_show(select: gr.Dropdown):
    if select == 'æ–°å»ºçŸ¥è¯†åº“':
        return gr.update(visible=True), gr.update(visible=False)
    else:
        return gr.update(visible=False), gr.update(visible=True)


def kb_name_select_then(kb_name):
    kb_dict = base.kb_list_to_dict([kb_name])
    kb_name = list(kb_dict.keys())[0]
    file_details = pd.DataFrame(base.get_kb_file_details(kb_name))
    if 'file_name' in file_details:
        db_file_list = file_details['file_name'].to_list()
        file_name = db_file_list[0]
        last_details = __get_kb_details_df(file_details, file_details["No"] == 1)
        last_fragment = __get_kb_fragment_df(kb_name, file_name)
        kb_file_list = gr.update(choices=db_file_list, value=file_name)
        kb_file_details = gr.DataFrame.update(value=last_details, label=f'{file_name}-æ–‡ä»¶è¯¦æƒ…')
        kb_file_fragment = gr.DataFrame.update(value=last_fragment, label=f'{file_name}-æ–‡ä»¶ç‰‡æ®µç¼–è¾‘')
    else:
        kb_file_list = gr.update(choices=[], value='')
        kb_file_details = gr.DataFrame.update(value=pd.DataFrame(data=copy.deepcopy(kb_config.file_details_template)))
        kb_file_fragment = gr.DataFrame.update(value=pd.DataFrame(data=copy.deepcopy(kb_config.file_fragment_template)))

    kb_name_tm = base.kb_details_to_dict()
    kb_info = base.get_kb_details_by_name(kb_name).get('kb_info', '')
    update_output = {
        'kb_name_list': gr.update(choices=base.kb_dict_to_list(kb_name_tm) + ['æ–°å»ºçŸ¥è¯†åº“']),
        'kb_info_txt': kb_info,
        'kb_file_list': kb_file_list,
        'kb_file_details': kb_file_details,
        'kb_file_fragment': kb_file_fragment
    }
    return list(update_output.values())


def kb_name_change_btn(name):
    if name:
        return gr.Button.update(variant='primary')
    else:
        return gr.Button.update(variant='secondary')


def kb_upload_btn(upload: gr.Files, cloud: str):
    if upload or URL(cloud).host:
        return gr.Button.update(variant='primary')
    else:
        return gr.Button.update(variant='secondary')


def kb_introduce_change_btn(kb_name, kb_info):
    kb_dict = base.kb_list_to_dict([kb_name])
    kb_name = list(kb_dict.keys())[0]
    resp = kb_doc_api.update_info(kb_name, kb_info)

    if not resp.data != 200:
        raise gr.Error(json.dumps(resp.__dict__, indent=4, ensure_ascii=False))
    else:
        return gr.update()
        # yield gr.update(value=func_box.spike_toast('æ›´æ–°çŸ¥è¯†åº“ç®€ä»‹æˆåŠŸ'), visible=True)
        # time.sleep(1)
        # yield gr.update(visible=False)


def kb_date_add_row(source_data: pd.DataFrame):
    # æ·»åŠ ä¸€è¡Œæ•°æ®
    last_index = source_data.iloc[-1].iloc[1]
    # æ£€æŸ¥æœ€åä¸€è¡Œçš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å¦ä¸ºæ•´æ•°ç±»å‹
    if last_index.dtype == 'int64':
        new_index = last_index + 1
    else:
        new_index = 'ErrorType'
    new_row_data = [uuid.uuid4(), new_index, '', '']
    source_data.loc[len(source_data)] = new_row_data

    return gr.update(value=source_data)


def kb_new_confirm(kb_name, kb_type, kb_model, kb_info):
    kb_name_tm = base.kb_details_to_dict()

    if not kb_name or not kb_type or not kb_model:
        keywords = {"çŸ¥è¯†åº“åç§°": kb_name, "å‘é‡ç±»å‹": kb_type, "Embedding æ¨¡å‹": kb_model}
        error_keyword = " - ".join([f"ã€{i}ã€‘" for i in keywords if not keywords[i]])
        raise gr.Error(f'ç¼ºå¤± {error_keyword} å­—æ®µ,æ— æ³•åˆ›å»º, ')

    kb_server_list = base.KBServiceFactory.get_service_by_name(kb_name)
    if kb_name in kb_name_tm or kb_server_list is not None:
        raise gr.Error(f'{kb_name} å·²å­˜åœ¨åŒåçŸ¥è¯†åº“ï¼Œè¯·é‡æ–°å‘½å')

    kb = base.KBServiceFactory.get_service(kb_name, kb_type, kb_model)
    kb.kb_info = kb_info
    try:
        kb.create_kb()
    except Exception as e:
        msg = f"åˆ›å»ºçŸ¥è¯†åº“å‡ºé”™ï¼š {e}"
        logger.error(f'{e.__class__.__name__}: {msg}')
        raise gr.Error(msg)
    select_name = base.kb_name_tm_merge(kb_name, kb_type, kb_model)
    new_output = {
        'new_clo': gr.update(visible=False),
        'edit_clo': gr.update(visible=True),
    }

    edit_output = {
        'kb_name_list': gr.update(choices=[select_name] + base.kb_dict_to_list(kb_name_tm) + ['æ–°å»ºçŸ¥è¯†åº“'],
                                  value=select_name),
        'kb_info_txt': kb_info,
        'kb_file_list': gr.update(choices=[], value=''),
        'kb_file_details': gr.DataFrame.update(value=pd.DataFrame(data=copy.deepcopy(kb_config.file_details_template))),
        'kb_file_fragment': gr.DataFrame.update(value=pd.DataFrame(data=copy.deepcopy(kb_config.file_fragment_template)))
    }
    return list(new_output.values()) + list(edit_output.values())


def __get_kb_details_df(file_details: pd.DataFrame, condition: pd.Series):
    select_document = file_details[condition]

    select_kb_details = copy.deepcopy(kb_config.file_details_template)

    select_kb_details.update({
        'æ–‡æ¡£åŠ è½½å™¨': select_document['document_loader'].to_list(),
        'åˆ†è¯å™¨': select_document['text_splitter'].to_list(),
        'æ–‡æ¡£ç‰‡æ®µæ•°é‡': select_document['docs_count'].to_list(),
        'å‘é‡åº“': select_document['in_db'].to_list(),
        'æºæ–‡ä»¶': select_document['in_folder'].to_list()
    })
    return pd.DataFrame(data=select_kb_details)


def __get_kb_fragment_df(kb_name, file_name):
    kb_fragment = copy.deepcopy(kb_config.file_fragment_template)

    info_fragment = kb_doc_api.search_docs(query='', knowledge_base_name=kb_name,
                                           top_k=1, score_threshold=1,
                                           file_name=file_name, metadata={})

    for i, v in enumerate(info_fragment):
        kb_fragment['id'].append(info_fragment[i].id)
        kb_fragment['N'].append(i + 1)
        kb_fragment['å†…å®¹'].append(info_fragment[i].page_content)
        kb_fragment['åˆ é™¤'].append('')
    return pd.DataFrame(data=kb_fragment)


def kb_file_update_confirm(upload_files: List, kb_name, kb_info, kb_max, kb_similarity, kb_tokenizer, kb_loader,
                           cloud_link, ipaddr: gr.Request):
    kb_name = list(base.kb_list_to_dict([kb_name]).keys())[0]
    user = func_box.user_client_mark(ipaddr)
    cloud_map, status = detach_cloud_links(cloud_link, {'ipaddr': user}, ['*'])
    if status:
        raise gr.Error(f'æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œ{cloud_map}')

    files = [f.name for f in upload_files] + list(cloud_map.keys())
    response = kb_doc_api.upload_docs(files=files, knowledge_base_name=kb_name, override=True,
                                      to_vector_store=True, chunk_size=kb_max, chunk_overlap=kb_similarity,
                                      loader_enhance=kb_loader, docs={}, not_refresh_vs_cache=False,
                                      text_splitter_name=kb_tokenizer)
    if response.code != 200:
        raise gr.Error(json.dumps(response.__dict__, indent=4, ensure_ascii=False))
    if response.data.get('failed_files'):
        raise gr.Error(json.dumps(response.data, indent=4, ensure_ascii=False))
    return kb_name_select_then(kb_name)


def kb_select_file(kb_name, kb_file: str):
    kb_name = list(base.kb_list_to_dict([kb_name]).keys())[0]
    file_details = pd.DataFrame(base.get_kb_file_details(kb_name))

    last_details = __get_kb_details_df(file_details, file_details["file_name"] == kb_file)
    last_fragment = __get_kb_fragment_df(kb_name, kb_file)

    return gr.update(value=last_details, label=f'{kb_file}-æ–‡ä»¶è¯¦æƒ…'), gr.update(value=last_fragment,
                                                                                 label=f'{kb_file}-æ–‡æ¡£ç‰‡æ®µç¼–è¾‘')


def kb_base_del(kb_name, del_confirm, _):
    if del_confirm == 'CANCELED':
        return gr.update(visible=False), gr.update(visible=True), gr.update()
    else:
        kb_name = list(base.kb_list_to_dict([kb_name]).keys())[0]
        response = kb_api.delete_kb(kb_name)
        if response.code != 200:
            raise gr.Error(json.dumps(response.__dict__, indent=4, ensure_ascii=False))
        kb_name_list = base.kb_dict_to_list(base.kb_details_to_dict()) + ['æ–°å»ºçŸ¥è¯†åº“']

        return gr.update(visible=True), gr.update(visible=False), gr.update(choices=kb_name_list,
                                                                            value='æ–°å»ºçŸ¥è¯†åº“')


def kb_docs_file_source_del(kb_name, kb_file, _):
    if kb_file == 'CANCELED':
        return gr.update(), gr.update(), gr.update(), gr.update()
    kb_name_d = list(base.kb_list_to_dict([kb_name]).keys())[0]
    resp = kb_doc_api.delete_docs(knowledge_base_name=kb_name_d, file_names=[kb_file],
                                  delete_content=True, not_refresh_vs_cache=False)
    if resp.code == 200 and not resp.data.get('failed_files'):
        toast = gr.update(
            value=func_box.spike_toast('å½»åº•åˆ é™¤æˆåŠŸ ğŸ´â€â˜ ï¸'),
            visible=True)
        _, _, file_list, details, fragment = kb_name_select_then(kb_name)
        yield toast, file_list, details, fragment
        time.sleep(1)
        yield gr.update(visible=False), file_list, details, fragment
    else:
        yield gr.Error(f'åˆ é™¤å¤±è´¥, {resp.__dict__}')


def kb_vector_del(kb_name, kb_file):
    kb_name_d = list(base.kb_list_to_dict([kb_name]).keys())[0]
    resp = kb_doc_api.delete_docs(knowledge_base_name=kb_name_d, file_names=[kb_file],
                                  delete_content=False, not_refresh_vs_cache=False)
    if resp.code == 200 and not resp.data.get('failed_files'):
        toast = gr.update(
            value=func_box.spike_toast('ä»…ä»å‘é‡åº“ä¸­åˆ é™¤ï¼Œåç»­è¯¥æ–‡æ¡£ä¸ä¼šè¢«å‘é‡å¬å›ï¼Œå¦‚éœ€é‡æ–°å¼•ç”¨ï¼Œé‡è½½å‘é‡æ•°æ®å³å¯'),
            visible=True)
        yield toast, *kb_select_file(kb_name, kb_file)
        time.sleep(1)
        yield gr.update(visible=False), gr.update(), gr.update()
    else:
        yield gr.Error(f'åˆ é™¤å¤±è´¥, {resp.__dict__}')


def kb_vector_reload(_, kb_name, kb_info, kb_max, kb_similarity, kb_tokenizer, kb_loader, kb_file):
    kb_name_k = list(base.kb_list_to_dict([kb_name]).keys())[0]
    resp = kb_doc_api.update_docs(
        knowledge_base_name=kb_name_k, file_names=[kb_file], docs={},
        chunk_size=kb_max, chunk_overlap=kb_similarity, override_custom_docs=True,
        loader_enhance=kb_loader, not_refresh_vs_cache=False,
        text_splitter_name=kb_tokenizer
    )
    if resp.code == 200 and not resp.data.get('failed_files'):
        yield gr.update(value=func_box.spike_toast('é‡è½½å‘é‡æ•°æ®æˆåŠŸ'), visible=True), *kb_select_file(kb_name, kb_file)
        time.sleep(1)
        yield gr.update(visible=False), gr.update(), gr.update()
    else:
        yield gr.Error(f'é‡è½½å‘é‡æ•°æ®å¤±è´¥, {resp.__dict__}'), gr.update(), gr.update()


def kb_base_changed_save(_, kb_name, kb_info, kb_max, kb_similarity, kb_tokenizer, kb_loader,
                         kb_file, kb_dataFrame: pd.DataFrame):
    kb_name = list(base.kb_list_to_dict([kb_name]).keys())[0]
    info_fragment = kb_doc_api.search_docs(query='', knowledge_base_name=kb_name,
                                           top_k=1, score_threshold=1,
                                           file_name=kb_file, metadata={})

    origin_docs = {}
    for x in info_fragment:
        origin_docs[x.id] = {"page_content": x.page_content,
                             "type": x.type,
                             "metadata": x.metadata}
    changed_docs = []
    for index, row in kb_dataFrame.iterrows():
        origin_doc = origin_docs.get(row['id'])
        if origin_doc:
            if row["åˆ é™¤"] not in ["Y", "y", 1, '1']:
                changed_docs.append({
                    "page_content": row["å†…å®¹"],
                    "type": origin_doc['type'],
                    "metadata": origin_doc["metadata"],
                })
            else:
                logger.warning(f'åˆ é™¤{row.get("id")}ç‰‡æ®µï¼š{origin_doc.get("page_content")}')
        else:
            changed_docs.append({
                "page_content": row["å†…å®¹"],
                "type": 'Document',
                "metadata": {"metadata": kb_file},
            })
    if changed_docs:
        resp = kb_doc_api.update_docs(
            knowledge_base_name=kb_name, file_names=[kb_file], docs={kb_file: changed_docs},
            chunk_size=kb_max, chunk_overlap=kb_similarity, override_custom_docs=False,
            loader_enhance=kb_loader, not_refresh_vs_cache=False,
            text_splitter_name=kb_tokenizer
        )
        if resp.code == 200 and not resp.data.get('failed_files'):
            yield gr.update(value=func_box.spike_toast('æ›´æ–°æˆåŠŸ'), visible=True), gr.update()
            time.sleep(1)
            yield gr.update(value=func_box.spike_toast('æ›´æ–°æˆåŠŸ'), visible=False), gr.update()
        else:
            yield gr.Error(f'æ›´æ–°å¤±è´¥, {resp.__dict__}')

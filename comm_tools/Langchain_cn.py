import os.path
from comm_tools import toolbox
from crazy_functions import crazy_utils
import gradio as gr
from comm_tools import func_box
from crazy_functions import crazy_box


def classification_filtering_tag(cls_select, cls_name, ipaddr):
    if cls_select == 'æ–°å»ºåˆ†ç±»':
        cls_select = cls_name
    elif cls_select == 'ä¸ªäººçŸ¥è¯†åº“':
        cls_select = os.path.join(cls_select, ipaddr)
    return cls_select


def knowledge_base_writing(cls_select, cls_name, links: str, select, name, kai_handle, ipaddr: gr.Request):
    # < --------------------è¯»å–å‚æ•°--------------- >
    cls_select = classification_filtering_tag(cls_select, cls_name, ipaddr.client.host)
    if not cls_select:
        yield 'æ–°å»ºåˆ†ç±»åç§°è¯·ä¸è¦ä¸ºç©º', '', gr.Dropdown.update(), gr.Dropdown.update(), kai_handle
        return
    vector_path = os.path.join(func_box.knowledge_path, cls_select)
    if name and select != 'æ–°å»ºçŸ¥è¯†åº“':
        kai_id = name
        os.rename(os.path.join(vector_path, select), os.path.join(vector_path, name))
        _, load_file = func_box.get_directory_list(vector_path, ipaddr.client.host)
        yield 'æ›´åæˆåŠŸï½', '', gr.Dropdown.update(), gr.Dropdown.update(choices=load_file, value=kai_id), kai_handle
    elif name and select == 'æ–°å»ºçŸ¥è¯†åº“': kai_id = name
    elif select and select != 'æ–°å»ºçŸ¥è¯†åº“': kai_id = select
    else: kai_id = func_box.created_atime()
    # < --------------------é™åˆ¶ä¸Šç­æ—¶é—´æ®µæ„å»ºçŸ¥è¯†åº“--------------- >
    reject_build_switch, = toolbox.get_conf('reject_build_switch')
    if reject_build_switch:
        if not func_box.check_expected_time():
            yield 'ä¸Šç­æ—¶é—´æ®µä¸å…è®¸å¯åŠ¨æ„å»ºçŸ¥è¯†åº“ä»»åŠ¡ï¼Œè‹¥æœ‰ç´§æ€¥ä»»åŠ¡è¯·è”ç³»ç®¡ç†å‘˜', '', gr.Dropdown.update(), gr.Dropdown.update(), kai_handle
            return
    # < --------------------è¯»å–æ–‡ä»¶æ­£å¼å¼€å§‹--------------- >
    yield 'å¼€å§‹å’¯å¼€å§‹å’¯ï½', '', gr.Dropdown.update(), gr.Dropdown.update(), kai_handle
    files = kai_handle['file_path']
    file_manifest = []
    spl,  = toolbox.get_conf('spl')
    # æœ¬åœ°æ–‡ä»¶
    error = ''
    for sp in spl:
        _, file_manifest_tmp, _ = crazy_utils.get_files_from_everything(files, type=f'.{sp}')
        file_manifest += file_manifest_tmp
    # ç½‘ç»œæ–‡ä»¶
    try:
        task_info, kdocs_manifest_tmp, _ = crazy_box.get_kdocs_from_everything(links, type='', ipaddr=ipaddr.client.host)
        if kdocs_manifest_tmp:
            error += task_info
            yield (f"", error, gr.Dropdown.update(), gr.Dropdown.update(), kai_handle)
    except:
        import traceback
        error_str = traceback.format_exc()
        error += f'æå–å‡ºé”™æ–‡ä»¶é”™è¯¯å•¦\n\n```\n{error_str}\n```'
        yield (f"", error, gr.Dropdown.update(), gr.Dropdown.update(), kai_handle)
        kdocs_manifest_tmp = []
    file_manifest += kdocs_manifest_tmp
    # < --------------------ç¼ºé™·æ–‡ä»¶æ‹†åˆ†--------------- >
    file_manifest = func_box.handling_defect_files(file_manifest)
    # < --------------------æ­£å¼å‡†å¤‡å¯åŠ¨ï¼--------------- >
    if len(file_manifest) == 0:
        types = "\t".join(f"`{s}`" for s in spl)
        link_type = f'\n\nç›®å½•: https://www.kdocs.cn/{func_box.html_tag_color("ent")}/41000207/{func_box.html_tag_color("130730080903")}\n\n' \
                    f'åˆ†äº«æ–‡ä»¶: https://www.kdocs.cn/l/{func_box.html_tag_color("cpfcxiGjEvqK")}'
        yield (f'æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯è¯»å–æ–‡ä»¶ï¼Œ å½“å‰æ”¯æŒè§£æçš„æœ¬åœ°æ–‡ä»¶æ ¼å¼å¦‚ä¸‹: \n\n{types}\n\nåœ¨çº¿æ–‡æ¡£é“¾æ¥æ”¯æŒå¦‚ä¸‹: {link_type}',
               error, gr.Dropdown.update(),
               gr.Dropdown.update(),  kai_handle)
        return
    # < -------------------é¢„çƒ­æ–‡æœ¬å‘é‡åŒ–æ¨¡ç»„--------------- >
    yield ('æ­£åœ¨åŠ è½½å‘é‡åŒ–æ¨¡å‹...', '', gr.Dropdown.update(), gr.Dropdown.update(), kai_handle)
    from langchain.embeddings.huggingface import HuggingFaceEmbeddings
    with toolbox.ProxyNetworkActivate():    # ä¸´æ—¶åœ°æ¿€æ´»ä»£ç†ç½‘ç»œ
        HuggingFaceEmbeddings(model_name="GanymedeNil/text2vec-large-chinese")
    # < -------------------æ„å»ºçŸ¥è¯†åº“--------------- >
    tab_show = [os.path.basename(i) for i in file_manifest]
    preprocessing_files = func_box.to_markdown_tabs(head=['æ–‡ä»¶'], tabs=[tab_show])
    yield (f'æ­£åœ¨å‡†å¤‡å°†ä»¥ä¸‹æ–‡ä»¶å‘é‡åŒ–ï¼Œç”ŸæˆçŸ¥è¯†åº“æ–‡ä»¶ï¼Œè‹¥æ–‡ä»¶æ•°æ®è¾ƒå¤šï¼Œå¯èƒ½éœ€è¦ç­‰å¾…å‡ å°æ—¶ï¼š\n\n{preprocessing_files}',
           error, gr.Dropdown.update(),
           gr.Dropdown.update(), kai_handle)
    with toolbox.ProxyNetworkActivate():    # ä¸´æ—¶åœ°æ¿€æ´»ä»£ç†ç½‘ç»œ
        kai = crazy_utils.knowledge_archive_interface(vs_path=vector_path)
        qa_handle, vs_path = kai.construct_vector_store(vs_id=kai_id, files=file_manifest)
    with open(os.path.join(vector_path, kai_id, ipaddr.client.host), mode='w') as f: pass
    _, kai_files = kai.get_init_file(kai_id)
    kai_handle['file_list'] = [os.path.basename(file) for file in kai_files if os.path.exists(file)]
    kai_files = func_box.to_markdown_tabs(head=['æ–‡ä»¶'], tabs=[tab_show])
    kai_handle['know_obj'].update({kai_id: qa_handle})
    kai_handle['know_name'] = kai_id
    load_list, user_list = func_box.get_directory_list(vector_path, ipaddr.client.host)
    yield (f'æ„å»ºå®Œæˆ, å½“å‰çŸ¥è¯†åº“å†…æœ‰æ•ˆçš„æ–‡ä»¶å¦‚ä¸‹, å·²è‡ªåŠ¨å¸®æ‚¨é€‰ä¸­çŸ¥è¯†åº“ï¼Œç°åœ¨ä½ å¯ä»¥ç•…å¿«çš„å¼€å§‹æé—®å•¦ï½\n\n{kai_files}',
           error, gr.Dropdown.update(value=cls_select),
           gr.Dropdown.update(value='æ–°å»ºçŸ¥è¯†åº“', choices=load_list),  kai_handle)


def knowledge_base_query(txt, kai_id, chatbot, history, llm_kwargs):
    # < -------------------ä¸ºç©ºæ—¶ï¼Œä¸å»æŸ¥è¯¢å‘é‡æ•°æ®åº“--------------- >
    if not txt: return txt
    # < -------------------æ£€ç´¢Prompt--------------- >
    new_txt = f'{txt}'
    if kai_id:
        chatbot.append([txt, f'æ­£åœ¨å°†é—®é¢˜å‘é‡åŒ–ï¼Œç„¶åå¯¹{func_box.html_tag_color(str(kai_id))}çŸ¥è¯†åº“è¿›è¡ŒåŒ¹é…'])
    for id in kai_id:   #
        if llm_kwargs['know_dict']['know_obj'].get(id, False):
            kai = llm_kwargs['know_dict']['know_obj'][id]
        else:
            know_cls = llm_kwargs['know_cls']
            know_cls = classification_filtering_tag(know_cls, know_cls, llm_kwargs['ipaddr'])
            vs_path = os.path.join(func_box.knowledge_path, know_cls)
            kai = crazy_utils.knowledge_archive_interface(vs_path=vs_path)
            llm_kwargs['know_dict']['know_obj'][id] = kai
        # < -------------------æŸ¥è¯¢å‘é‡æ•°æ®åº“--------------- >
        yield from toolbox.update_ui(chatbot=chatbot, history=history)  # åˆ·æ–°ç•Œé¢
        vector_config = llm_kwargs['vector']
        resp, prompt, _ok = kai.answer_with_archive_by_id(txt, id,
                                                          VECTOR_SEARCH_SCORE_THRESHOLD=vector_config['score'],
                                                          VECTOR_SEARCH_TOP_K=vector_config['top-k'],
                                                          CHUNK_SIZE=vector_config['size'])
        if resp:
            referenced_documents = "\n".join(
                [f"{k}: " + doc.page_content for k, doc in enumerate(resp['source_documents'])])
            new_txt += f'\nä»¥ä¸‹ä¸‰ä¸ªå¼•å·å†…çš„æ˜¯{id}æä¾›çš„å‚è€ƒæ–‡æ¡£ï¼š\n"""\n{referenced_documents}\n"""'
    return new_txt

def obtain_classification_knowledge_base(cls_name, ipaddr: gr.Request):
    if cls_name == 'ä¸ªäººçŸ¥è¯†åº“':
        load_path = os.path.join(func_box.knowledge_path, 'ä¸ªäººçŸ¥è¯†åº“', ipaddr.client.host)
    else:
        load_path = os.path.join(func_box.knowledge_path, cls_name)
    load_list, user_list = func_box.get_directory_list(load_path, ipaddr.client.host)
    status = f"ä½ åªèƒ½é‡æ„è‡ªå·±ä¸Šä¼ çš„çŸ¥è¯†åº“å“¦ ğŸ˜" \
             f"\n\n{func_box.to_markdown_tabs(head=['å¯ç¼–è¾‘çŸ¥è¯†åº“', 'å¯ç”¨çŸ¥è¯†åº“'], tabs=[user_list, load_list], column=False)}\n\n"
    return gr.Dropdown.update(choices=user_list), gr.Dropdown.update(choices=load_list, label=f'{cls_name}'), status


def obtaining_knowledge_base_files(cls_select, cls_name, vs_id, chatbot, kai_handle, ipaddr: gr.Request):
    if vs_id:
        cls_select = classification_filtering_tag(cls_select, cls_name, ipaddr.client.host)
        vs_path = os.path.join(func_box.knowledge_path, cls_select)
        if isinstance(chatbot, toolbox.ChatBotWithCookies):
            pass
        else:
            chatbot = toolbox.ChatBotWithCookies(chatbot)
            chatbot.write_list(chatbot)
        chatbot.append([None, f'æ­£åœ¨æ£€æŸ¥çŸ¥è¯†åº“å†…æ–‡ä»¶{"  ".join([func_box.html_tag_color(i)for i in vs_id])}'])
        yield chatbot, gr.Column.update(visible=False), 'ğŸƒğŸ»â€ æ­£åœ¨åŠªåŠ›è½®è¯¢ä¸­....è¯·ç¨ç­‰ï¼Œ tipsï¼šçŸ¥è¯†åº“å¯ä»¥å¤šé€‰ï¼Œä½†åªä¼šé¢„åŠ è½½ç¬¬ä¸€ä¸ªé€‰ä¸­çš„çŸ¥è¯†åº“ï½ï¸', kai_handle
        kai_files = {}
        for id in vs_id:
            if kai_handle['know_obj'].get(id, None):
                kai = kai_handle['know_obj'][id]
            else:
                kai = crazy_utils.knowledge_archive_interface(vs_path=vs_path)
            qa_handle, _dict = kai.get_init_file(vs_id=id)
            kai_files.update(_dict)
            kai_handle['know_obj'].update({id: qa_handle})
        tabs = [[_id, func_box.html_view_blank(file), kai_files[file][_id]] for file in kai_files for _id in kai_files[file]]
        kai_handle['file_list'] = [os.path.basename(file) for file in kai_files if os.path.exists(file)]
        chatbot.append([None, f'æ£€æŸ¥å®Œæˆï¼Œå½“å‰é€‰æ‹©çš„çŸ¥è¯†åº“å†…å¯ç”¨æ–‡ä»¶å¦‚ä¸‹ï¼š'
                              f'\n\n {func_box.to_markdown_tabs(head=["æ‰€å±çŸ¥è¯†åº“", "æ–‡ä»¶", "æ–‡ä»¶ç±»å‹"], tabs=tabs, column=True)}\n\n'
                              f'ğŸ¤© å¿«æ¥å‘æˆ‘æé—®å§ï½'])
        yield chatbot, gr.Column.update(visible=False), 'âœ… æ£€æŸ¥å®Œæˆ', kai_handle
    else:
        yield chatbot, gr.update(), 'Done', kai_handle


